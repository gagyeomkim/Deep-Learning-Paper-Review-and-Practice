{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOTm75R3oPv/FfnMXT5hXOU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagyeomkim/Deep-Learning-Paper-Review-and-Practice/blob/main/code_practice/Word2Vec1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Efficient Estimation of Word Representations in Vector Space(2013)** 실습"
      ],
      "metadata": {
        "id": "H6BE5mPF94y5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 본 코드는 Word2Vec의 방법 중에서도 **Skip-Gram** 방식을 구현합니다.\n",
        "    - 본 논문은 자연어 처리 기법의 기본적인 구성을 이해하고 공부하는 데에 도움을 줍니다.\n",
        "- 코드 실행전에 **[런타임] -> [런타임 유형 변경]**에서 유형을 **GPU**로 설정합니다."
      ],
      "metadata": {
        "id": "1ktCCJjljEIB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "추가적인 reference\n",
        "- http://blog.cedartrees.co.kr/index.php/category/tech-note/pytorch/\n",
        "- https://ratsgo.github.io/from%20frequency%20to%20semantics/2017/03/30/word2vec/"
      ],
      "metadata": {
        "id": "xf_dHWKkpgxS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Import Modules"
      ],
      "metadata": {
        "id": "PnS7y7m2AJNr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7dqMNLxhMDO"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 전처리(Preprocessing)"
      ],
      "metadata": {
        "id": "psYn6toHAMYe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- corpus 데이터를 토큰화해서 보관"
      ],
      "metadata": {
        "id": "2LZzWT5bATlK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = [\n",
        "    'he is a king',\n",
        "    'she is a queen',\n",
        "    'he is a man',\n",
        "    'she is a woman',\n",
        "    'warsaw is poland capital',\n",
        "    'berlin is germany capital',\n",
        "    'paris is france capital',\n",
        "    'seoul is korea capital',\n",
        "    'bejing is china capital',\n",
        "    'tokyo is japan capital',\n",
        "]\n",
        "\n",
        "def tokenize_corpus(corpus):\n",
        "    tokens = [x.split() for x in corpus]\n",
        "\n",
        "    # 구조 살펴보기\n",
        "    [print(f\"x: {x}\") for x in corpus]\n",
        "    [print(f\"x.split(): {x.split()}\") for x in corpus]\n",
        "    print(tokens)\n",
        "\n",
        "    return tokens\n",
        "\n",
        "tokenized_corpus = tokenize_corpus(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6pAHsIPEh-fR",
        "outputId": "69ace7fc-179a-4dff-8a04-ac2cbba381d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x: he is a king\n",
            "x: she is a queen\n",
            "x: he is a man\n",
            "x: she is a woman\n",
            "x: warsaw is poland capital\n",
            "x: berlin is germany capital\n",
            "x: paris is france capital\n",
            "x: seoul is korea capital\n",
            "x: bejing is china capital\n",
            "x: tokyo is japan capital\n",
            "x.split(): ['he', 'is', 'a', 'king']\n",
            "x.split(): ['she', 'is', 'a', 'queen']\n",
            "x.split(): ['he', 'is', 'a', 'man']\n",
            "x.split(): ['she', 'is', 'a', 'woman']\n",
            "x.split(): ['warsaw', 'is', 'poland', 'capital']\n",
            "x.split(): ['berlin', 'is', 'germany', 'capital']\n",
            "x.split(): ['paris', 'is', 'france', 'capital']\n",
            "x.split(): ['seoul', 'is', 'korea', 'capital']\n",
            "x.split(): ['bejing', 'is', 'china', 'capital']\n",
            "x.split(): ['tokyo', 'is', 'japan', 'capital']\n",
            "[['he', 'is', 'a', 'king'], ['she', 'is', 'a', 'queen'], ['he', 'is', 'a', 'man'], ['she', 'is', 'a', 'woman'], ['warsaw', 'is', 'poland', 'capital'], ['berlin', 'is', 'germany', 'capital'], ['paris', 'is', 'france', 'capital'], ['seoul', 'is', 'korea', 'capital'], ['bejing', 'is', 'china', 'capital'], ['tokyo', 'is', 'japan', 'capital']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 단어들의 중복을 제거하여 vocabulary 리스트를 만들고\n",
        "- word2idx, idx2word dict를 만들기"
      ],
      "metadata": {
        "id": "yzugRDfdi7u2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary = []\n",
        "for sentence in tokenized_corpus:\n",
        "    for token in sentence:\n",
        "        if token not in vocabulary:\n",
        "            vocabulary.append(token)\n",
        "\n",
        "# word -> idx\n",
        "word2idx = {w: idx for (idx, w) in enumerate(vocabulary)}\n",
        "print(word2idx)\n",
        "\n",
        "# idx -> word\n",
        "idx2word = {idx: w for (idx, w) in enumerate(vocabulary)}\n",
        "print(idx2word)\n",
        "\n",
        "vocabulary_size = len(vocabulary)\n",
        "print(f\"vocabulary_size: {vocabulary_size}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2nzGe2riKEv",
        "outputId": "037a3ea9-b0fd-4d6b-bc0b-27d9a34c3d9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'he': 0, 'is': 1, 'a': 2, 'king': 3, 'she': 4, 'queen': 5, 'man': 6, 'woman': 7, 'warsaw': 8, 'poland': 9, 'capital': 10, 'berlin': 11, 'germany': 12, 'paris': 13, 'france': 14, 'seoul': 15, 'korea': 16, 'bejing': 17, 'china': 18, 'tokyo': 19, 'japan': 20}\n",
            "{0: 'he', 1: 'is', 2: 'a', 3: 'king', 4: 'she', 5: 'queen', 6: 'man', 7: 'woman', 8: 'warsaw', 9: 'poland', 10: 'capital', 11: 'berlin', 12: 'germany', 13: 'paris', 14: 'france', 15: 'seoul', 16: 'korea', 17: 'bejing', 18: 'china', 19: 'tokyo', 20: 'japan'}\n",
            "vocabulary_size: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `window_size`를 지정하여 (중심단어, 주변단어)의 쌍을 가진 `idx_pairs` 생성"
      ],
      "metadata": {
        "id": "Lzke81f8AX3j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "window_size = 2 # 주변의 단어를 몇개까지 학습에 이용할 것인가를 결정해주는 하이퍼파라미터(양 옆 포함)\n",
        "idx_pairs = []\n",
        "\n",
        "for sentence in tokenized_corpus:\n",
        "    indices = [word2idx[word] for word in sentence] # word -> 정수index로 변환\n",
        "    # print(indices)  # (문장별로=1, 토큰개수=4)\n",
        "    for center_word_pos in range(len(indices)): # (0, 1, 2, 3)으로 돌아가면서 중심단어 pos 골라짐\n",
        "        for w in range(-window_size, window_size + 1):  # -2이상, 3 미만\n",
        "            context_word_pos = center_word_pos + w  # 0부터 시작하는 주변 단어 index. 주변으로 윈도우크기만큼 봄.\n",
        "            if context_word_pos < 0 or context_word_pos >= len(indices) or center_word_pos == context_word_pos:\n",
        "                # 1. 문장을 벗어나는 범위이거나\n",
        "                # 2. 중심 단어랑 주변단어가 같은 경우는\n",
        "                continue;\n",
        "            context_word_idx = indices[context_word_pos]    # 주변 단어의 idx를 확인\n",
        "            # print(context_word_idx)\n",
        "            idx_pairs.append((indices[center_word_pos], context_word_idx))  # (중심단어, 주변단어) 튜플로 리스트에 넣음\n",
        "            # print(idx_pairs)    # (중심단어, 주변단어) 튜플들이 리스트에 추가되는 것 확인 -> [(중심단어, 주변단어)...]\n",
        "idx_pairs = np.array(idx_pairs) # 튜플들이 array로 변경됨 -> [[중심단어, 주변단어]...]\n",
        "# print(idx_pairs)"
      ],
      "metadata": {
        "id": "6GxVEayqjm8v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - 왜 `context_word_pos > len(indices)`이 아니라\n",
        "`context_word_pos >= len(indices)`인가?\n",
        "    - context_word_pos는 index이기 때문에 len(indices)-1까지만 가능함. 따라서 `> len(indices)`로 조건을 주면 out of range\n",
        "    - 예를 들어, 현재 단어는 4개이지만 3이 중심단어일 경우 1 2 4만 주변 단어로 취급\n",
        "        ```text\n",
        "        1 2 3 4\n",
        "        ```"
      ],
      "metadata": {
        "id": "AHzCBPeZnEGk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(idx_pairs[0:10])  # 10개만 출력 / 중심단어를 통해서 -> 주변에 나올 수 있는 단어 예측하는 방법으로 학습 진행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24djBsHJpIBM",
        "outputId": "a320e2b6-0c8a-48f9-926c-1e886b89d9f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1]\n",
            " [0 2]\n",
            " [1 0]\n",
            " [1 2]\n",
            " [1 3]\n",
            " [2 0]\n",
            " [2 1]\n",
            " [2 3]\n",
            " [3 1]\n",
            " [3 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 입력 데이터를 one-hot 형태로 변경함(`nn.Embedding`으로 구하지 않고 직접 구현)"
      ],
      "metadata": {
        "id": "AMrsdnPvplw5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_input_layer(word_idx):\n",
        "    # print(np.eye(vocabulary_size))  # vocabulary size만큼 Identity Matrix 생성후\n",
        "    # print(np.eye(vocabulary_size)[word_idx])    # [word_idx]로 첫번째 차원(행)에서 중심 단어에 해당하는 부분만 가져옴\n",
        "    return np.eye(vocabulary_size)[word_idx]    # 중심단어에 대한 원-핫 벡터 리턴\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for data, target in idx_pairs:\n",
        "# for data, target in idx_pairs[:5]:  #\n",
        "    # data: 중심단어 인덱스\n",
        "    # target: 주변단어 인덱스\n",
        "    X.append(get_input_layer(data)) # 중심단어의 원핫 벡터 저장\n",
        "    # print(f\"X: {X}\")\n",
        "    y.append(target)    # 바로 주변 단어에 해당하는 정수인덱스 저장\n",
        "    # print(f\"y: {y}\")\n",
        "\n",
        "# print(X)\n",
        "# print(y)\n",
        "\n",
        "X = torch.FloatTensor(np.array(X))  # 텐서로 변경\n",
        "y = torch.Tensor(np.array(y)).long()    # long type의 텐서로 변경\n",
        "print(X)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPoHcywBkvTd",
        "outputId": "4b7bb694-47b9-4bec-e8a0-a329e0a13c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 1.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
            "tensor([ 1,  2,  0,  2,  3,  0,  1,  3,  1,  2,  1,  2,  4,  2,  5,  4,  1,  5,\n",
            "         1,  2,  1,  2,  0,  2,  6,  0,  1,  6,  1,  2,  1,  2,  4,  2,  7,  4,\n",
            "         1,  7,  1,  2,  1,  9,  8,  9, 10,  8,  1, 10,  1,  9,  1, 12, 11, 12,\n",
            "        10, 11,  1, 10,  1, 12,  1, 14, 13, 14, 10, 13,  1, 10,  1, 14,  1, 16,\n",
            "        15, 16, 10, 15,  1, 10,  1, 16,  1, 18, 17, 18, 10, 17,  1, 10,  1, 18,\n",
            "         1, 20, 19, 20, 10, 19,  1, 10,  1, 20])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - `y = torch.Tensor(np.array(y)).long()    # long type의 텐서로 변경`에서 .long 말고 .int쓰면 안되는지?\n",
        "    - `nn.CrossEntropyLoss`나 `nn.NLLLoss`같은 손실함수들은 타겟값으로 long 타입의 텐서(LongTensor)를 요구하기에 .int()쓰면 런타임 에러 발생\n",
        "    - nn.Embedding에서 값을 인덱싱할 때, 사용되는 텐서는 반드시 long 타입이어야함\n",
        "    - 즉, 파이토치는 long 타입을 기준으로 설계되었으므로 반드시 .long 써야함"
      ],
      "metadata": {
        "id": "hgJcTXLcrt2G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Word2Vec 모듈**"
      ],
      "metadata": {
        "id": "698-tipxsIRW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Word2VecModel(nn.Module):\n",
        "    def __init__(self,inout_dim):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(inout_dim, 2)  # (,inout_dim), -> (,2) - 2차원 벡터로 압축\n",
        "        self.linear2 = nn.Linear(2, inout_dim)  # (,2) -> (,inout_dim)  - output이 되는 원-핫 벡터 생성을 위해 다시 원본 크기로 돌림\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear2(self.linear1(x))\n",
        "\n",
        "print(X.size()) # (주변단어와 엮인 중심단어개수(중복 O), Vocabulary 크기)\n",
        "print(X.size(dim=-1))   # (Vocabulary크기 전달)\n",
        "model = Word2VecModel(X.size(dim=-1))   # inout_dim = vocabulary 크기(feature 수)로 설정"
      ],
      "metadata": {
        "id": "d_CY54LCqHuj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d57bb761-eefd-4455-f405-412b4efb9291"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 21])\n",
            "21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- nn.Linear의 선형 변환 체크"
      ],
      "metadata": {
        "id": "yZbkqM86BQfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m = nn.Linear(20, 30)\n",
        "input = torch.randn(128, 20) # 첫번째 차원은 nn.Linear에 의해 변경되지 않음. 입력 텐서의 마지막 차원에 대해서만 선형 변환을 적용\n",
        "                             # 보통 첫번째 차원은 배치크기, 마지막 차원은 feature 수를 사용함.\n",
        "output = m(input)\n",
        "print(output.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j99R9fIlsY1t",
        "outputId": "1beb8ae5-39ae-4893-ae6b-562a79648336"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m2 = nn.Linear(40, 30)\n",
        "input2 = torch.randn(128, 20, 40) # 첫번째 차원은 nn.Linear에 의해 변경되지 않음. 입력 텐서의 마지막 차원에 대해서만 선형 변환을 적용\n",
        "                                 # 보통 첫번째 차원은 배치크기, 마지막 차원은 feature 수를 사용함.\n",
        "output2 = m2(input2)\n",
        "print(output2.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "629JK37xtNZ9",
        "outputId": "003c4d53-39b8-4ac6-d6d5-de8e73b7616b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 20, 30])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 학습(training)"
      ],
      "metadata": {
        "id": "CPx_d8CbBTtA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# optimizer 설정\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "nb_epochs = 100\n",
        "for epoch in range(nb_epochs + 1):  # 100번의 에폭을 돎\n",
        "\n",
        "    # H(x) 계산\n",
        "    # 훈련데이터를 다 도는게 1번의 epoch. 배치처리 안해줬으므로 한번 훈련할때마다 1번의 에폭\n",
        "    prediction = model(X)   # X: (주변단어와 엮인 중심단어개수(중복 O)=100, Vocabulary크기=21) / prediction(100, 21)\n",
        "    print(prediction)   # prediction은 (주변단어와 엮인 중심단어개수, 이 중심단어일 때 주변 단어 예측 점수)\n",
        "\n",
        "    # cost 계산\n",
        "    # cross_entropy함수는 softmax함수를 내부적으로 포함함.\n",
        "    # cross_entropy = log_softmax + nll_loss(Negative Log Likelihood: -(y_hat - y))\n",
        "    cost = F.cross_entropy(prediction, y)   # cross_entropy: 인자: (예측, 실제값)\n",
        "\n",
        "    # cost로 H(x) 개선\n",
        "    optimizer.zero_grad()   # 안넣으면?: 역전파를 시키면 이전 루프에서 .grad에 저장된 값이 다음 루프의 업데이트에도 간섭을 해서 원하는 방향으로 학습이 안된다\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    # 20번마다 로그 출력\n",
        "    if epoch%100 == 0:\n",
        "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
        "            epoch, nb_epochs, cost.item()\n",
        "        ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz4LZhywsemu",
        "outputId": "fd23f472-5192-4fc0-b4a3-313c5f138027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5392, -0.4769, -0.2926,  ...,  0.1269,  0.1353,  0.0157],\n",
            "        [-0.5392, -0.4769, -0.2926,  ...,  0.1269,  0.1353,  0.0157],\n",
            "        [-0.5990, -0.5433, -0.2732,  ...,  0.1915,  0.0990,  0.0957],\n",
            "        ...,\n",
            "        [-0.5684, -0.4897, -0.2949,  ...,  0.1456,  0.1346,  0.0633],\n",
            "        [-0.3850, -0.3138, -0.3378,  ..., -0.0344,  0.2222, -0.1939],\n",
            "        [-0.3850, -0.3138, -0.3378,  ..., -0.0344,  0.2222, -0.1939]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch    0/100 Cost: 3.262854\n",
            "tensor([[-0.5365, -0.4741, -0.2918,  ...,  0.1241,  0.1350,  0.0125],\n",
            "        [-0.5365, -0.4741, -0.2918,  ...,  0.1241,  0.1350,  0.0125],\n",
            "        [-0.5961, -0.5405, -0.2722,  ...,  0.1885,  0.0986,  0.0923],\n",
            "        ...,\n",
            "        [-0.5656, -0.4870, -0.2940,  ...,  0.1427,  0.1343,  0.0600],\n",
            "        [-0.3826, -0.3110, -0.3374,  ..., -0.0368,  0.2218, -0.1968],\n",
            "        [-0.3826, -0.3110, -0.3374,  ..., -0.0368,  0.2218, -0.1968]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5338, -0.4713, -0.2910,  ...,  0.1213,  0.1346,  0.0093],\n",
            "        [-0.5338, -0.4713, -0.2910,  ...,  0.1213,  0.1346,  0.0093],\n",
            "        [-0.5932, -0.5377, -0.2712,  ...,  0.1855,  0.0982,  0.0889],\n",
            "        ...,\n",
            "        [-0.5628, -0.4843, -0.2931,  ...,  0.1398,  0.1340,  0.0567],\n",
            "        [-0.3803, -0.3082, -0.3370,  ..., -0.0392,  0.2214, -0.1996],\n",
            "        [-0.3803, -0.3082, -0.3370,  ..., -0.0392,  0.2214, -0.1996]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5310, -0.4685, -0.2901,  ...,  0.1185,  0.1342,  0.0061],\n",
            "        [-0.5310, -0.4685, -0.2901,  ...,  0.1185,  0.1342,  0.0061],\n",
            "        [-0.5903, -0.5349, -0.2702,  ...,  0.1825,  0.0978,  0.0855],\n",
            "        ...,\n",
            "        [-0.5600, -0.4816, -0.2922,  ...,  0.1369,  0.1338,  0.0534],\n",
            "        [-0.3781, -0.3054, -0.3367,  ..., -0.0416,  0.2210, -0.2024],\n",
            "        [-0.3781, -0.3054, -0.3367,  ..., -0.0416,  0.2210, -0.2024]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5283, -0.4657, -0.2893,  ...,  0.1157,  0.1338,  0.0028],\n",
            "        [-0.5283, -0.4657, -0.2893,  ...,  0.1157,  0.1338,  0.0028],\n",
            "        [-0.5875, -0.5321, -0.2693,  ...,  0.1796,  0.0974,  0.0821],\n",
            "        ...,\n",
            "        [-0.5572, -0.4790, -0.2914,  ...,  0.1341,  0.1335,  0.0501],\n",
            "        [-0.3758, -0.3026, -0.3363,  ..., -0.0439,  0.2206, -0.2052],\n",
            "        [-0.3758, -0.3026, -0.3363,  ..., -0.0439,  0.2206, -0.2052]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-5.2565e-01, -4.6295e-01, -2.8856e-01,  ...,  1.1289e-01,\n",
            "          1.3346e-01, -3.6132e-04],\n",
            "        [-5.2565e-01, -4.6295e-01, -2.8856e-01,  ...,  1.1289e-01,\n",
            "          1.3346e-01, -3.6132e-04],\n",
            "        [-5.8463e-01, -5.2926e-01, -2.6831e-01,  ...,  1.7665e-01,\n",
            "          9.7038e-02,  7.8750e-02],\n",
            "        ...,\n",
            "        [-5.5447e-01, -4.7626e-01, -2.9049e-01,  ...,  1.3120e-01,\n",
            "          1.3321e-01,  4.6782e-02],\n",
            "        [-3.7350e-01, -2.9975e-01, -3.3590e-01,  ..., -4.6303e-02,\n",
            "          2.2020e-01, -2.0793e-01],\n",
            "        [-3.7350e-01, -2.9975e-01, -3.3590e-01,  ..., -4.6303e-02,\n",
            "          2.2020e-01, -2.0793e-01]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5230, -0.4602, -0.2878,  ...,  0.1101,  0.1331, -0.0036],\n",
            "        [-0.5230, -0.4602, -0.2878,  ...,  0.1101,  0.1331, -0.0036],\n",
            "        [-0.5818, -0.5265, -0.2674,  ...,  0.1737,  0.0966,  0.0754],\n",
            "        ...,\n",
            "        [-0.5517, -0.4736, -0.2896,  ...,  0.1283,  0.1329,  0.0435],\n",
            "        [-0.3712, -0.2969, -0.3355,  ..., -0.0487,  0.2198, -0.2107],\n",
            "        [-0.3712, -0.2969, -0.3355,  ..., -0.0487,  0.2198, -0.2107]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5203, -0.4574, -0.2870,  ...,  0.1074,  0.1327, -0.0067],\n",
            "        [-0.5203, -0.4574, -0.2870,  ...,  0.1074,  0.1327, -0.0067],\n",
            "        [-0.5790, -0.5237, -0.2664,  ...,  0.1708,  0.0963,  0.0721],\n",
            "        ...,\n",
            "        [-0.5489, -0.4709, -0.2888,  ...,  0.1255,  0.1327,  0.0402],\n",
            "        [-0.3690, -0.2941, -0.3352,  ..., -0.0510,  0.2194, -0.2135],\n",
            "        [-0.3690, -0.2941, -0.3352,  ..., -0.0510,  0.2194, -0.2135]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5176, -0.4546, -0.2862,  ...,  0.1046,  0.1323, -0.0099],\n",
            "        [-0.5176, -0.4546, -0.2862,  ...,  0.1046,  0.1323, -0.0099],\n",
            "        [-0.5761, -0.5209, -0.2655,  ...,  0.1679,  0.0959,  0.0688],\n",
            "        ...,\n",
            "        [-0.5462, -0.4682, -0.2879,  ...,  0.1227,  0.1324,  0.0370],\n",
            "        [-0.3667, -0.2913, -0.3348,  ..., -0.0533,  0.2190, -0.2162],\n",
            "        [-0.3667, -0.2913, -0.3348,  ..., -0.0533,  0.2190, -0.2162]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5150, -0.4518, -0.2855,  ...,  0.1019,  0.1319, -0.0131],\n",
            "        [-0.5150, -0.4518, -0.2855,  ...,  0.1019,  0.1319, -0.0131],\n",
            "        [-0.5734, -0.5181, -0.2646,  ...,  0.1650,  0.0955,  0.0655],\n",
            "        ...,\n",
            "        [-0.5435, -0.4655, -0.2871,  ...,  0.1198,  0.1321,  0.0337],\n",
            "        [-0.3645, -0.2885, -0.3345,  ..., -0.0557,  0.2186, -0.2190],\n",
            "        [-0.3645, -0.2885, -0.3345,  ..., -0.0557,  0.2186, -0.2190]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5123, -0.4490, -0.2847,  ...,  0.0991,  0.1316, -0.0162],\n",
            "        [-0.5123, -0.4490, -0.2847,  ...,  0.0991,  0.1316, -0.0162],\n",
            "        [-0.5706, -0.5153, -0.2636,  ...,  0.1621,  0.0951,  0.0622],\n",
            "        ...,\n",
            "        [-0.5407, -0.4628, -0.2862,  ...,  0.1170,  0.1318,  0.0305],\n",
            "        [-0.3623, -0.2857, -0.3342,  ..., -0.0580,  0.2182, -0.2217],\n",
            "        [-0.3623, -0.2857, -0.3342,  ..., -0.0580,  0.2182, -0.2217]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5097, -0.4462, -0.2840,  ...,  0.0964,  0.1312, -0.0194],\n",
            "        [-0.5097, -0.4462, -0.2840,  ...,  0.0964,  0.1312, -0.0194],\n",
            "        [-0.5678, -0.5125, -0.2627,  ...,  0.1593,  0.0947,  0.0589],\n",
            "        ...,\n",
            "        [-0.5380, -0.4601, -0.2854,  ...,  0.1142,  0.1315,  0.0273],\n",
            "        [-0.3600, -0.2829, -0.3338,  ..., -0.0603,  0.2178, -0.2244],\n",
            "        [-0.3600, -0.2829, -0.3338,  ..., -0.0603,  0.2178, -0.2244]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5071, -0.4434, -0.2832,  ...,  0.0937,  0.1308, -0.0225],\n",
            "        [-0.5071, -0.4434, -0.2832,  ...,  0.0937,  0.1308, -0.0225],\n",
            "        [-0.5651, -0.5098, -0.2618,  ...,  0.1564,  0.0943,  0.0557],\n",
            "        ...,\n",
            "        [-0.5353, -0.4574, -0.2846,  ...,  0.1114,  0.1313,  0.0241],\n",
            "        [-0.3578, -0.2801, -0.3335,  ..., -0.0626,  0.2174, -0.2272],\n",
            "        [-0.3578, -0.2801, -0.3335,  ..., -0.0626,  0.2174, -0.2272]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5045, -0.4407, -0.2825,  ...,  0.0910,  0.1304, -0.0256],\n",
            "        [-0.5045, -0.4407, -0.2825,  ...,  0.0910,  0.1304, -0.0256],\n",
            "        [-0.5623, -0.5070, -0.2609,  ...,  0.1536,  0.0939,  0.0524],\n",
            "        ...,\n",
            "        [-0.5326, -0.4548, -0.2838,  ...,  0.1086,  0.1310,  0.0209],\n",
            "        [-0.3556, -0.2772, -0.3332,  ..., -0.0649,  0.2170, -0.2299],\n",
            "        [-0.3556, -0.2772, -0.3332,  ..., -0.0649,  0.2170, -0.2299]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.5019, -0.4379, -0.2818,  ...,  0.0883,  0.1300, -0.0287],\n",
            "        [-0.5019, -0.4379, -0.2818,  ...,  0.0883,  0.1300, -0.0287],\n",
            "        [-0.5596, -0.5043, -0.2601,  ...,  0.1507,  0.0935,  0.0492],\n",
            "        ...,\n",
            "        [-0.5300, -0.4521, -0.2830,  ...,  0.1059,  0.1307,  0.0177],\n",
            "        [-0.3534, -0.2744, -0.3329,  ..., -0.0672,  0.2166, -0.2326],\n",
            "        [-0.3534, -0.2744, -0.3329,  ..., -0.0672,  0.2166, -0.2326]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4993, -0.4351, -0.2810,  ...,  0.0856,  0.1296, -0.0318],\n",
            "        [-0.4993, -0.4351, -0.2810,  ...,  0.0856,  0.1296, -0.0318],\n",
            "        [-0.5569, -0.5015, -0.2592,  ...,  0.1479,  0.0931,  0.0460],\n",
            "        ...,\n",
            "        [-0.5273, -0.4494, -0.2822,  ...,  0.1031,  0.1304,  0.0145],\n",
            "        [-0.3513, -0.2716, -0.3326,  ..., -0.0694,  0.2162, -0.2353],\n",
            "        [-0.3513, -0.2716, -0.3326,  ..., -0.0694,  0.2162, -0.2353]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4967, -0.4323, -0.2803,  ...,  0.0830,  0.1292, -0.0349],\n",
            "        [-0.4967, -0.4323, -0.2803,  ...,  0.0830,  0.1292, -0.0349],\n",
            "        [-0.5542, -0.4988, -0.2583,  ...,  0.1451,  0.0927,  0.0429],\n",
            "        ...,\n",
            "        [-0.5247, -0.4467, -0.2814,  ...,  0.1004,  0.1301,  0.0113],\n",
            "        [-0.3491, -0.2688, -0.3323,  ..., -0.0717,  0.2157, -0.2380],\n",
            "        [-0.3491, -0.2688, -0.3323,  ..., -0.0717,  0.2157, -0.2380]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4942, -0.4296, -0.2796,  ...,  0.0803,  0.1289, -0.0380],\n",
            "        [-0.4942, -0.4296, -0.2796,  ...,  0.0803,  0.1289, -0.0380],\n",
            "        [-0.5516, -0.4960, -0.2575,  ...,  0.1424,  0.0923,  0.0397],\n",
            "        ...,\n",
            "        [-0.5220, -0.4441, -0.2807,  ...,  0.0976,  0.1299,  0.0082],\n",
            "        [-0.3469, -0.2660, -0.3320,  ..., -0.0740,  0.2153, -0.2406],\n",
            "        [-0.3469, -0.2660, -0.3320,  ..., -0.0740,  0.2153, -0.2406]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4916, -0.4268, -0.2789,  ...,  0.0777,  0.1285, -0.0410],\n",
            "        [-0.4916, -0.4268, -0.2789,  ...,  0.0777,  0.1285, -0.0410],\n",
            "        [-0.5489, -0.4933, -0.2566,  ...,  0.1396,  0.0919,  0.0366],\n",
            "        ...,\n",
            "        [-0.5194, -0.4414, -0.2799,  ...,  0.0949,  0.1296,  0.0050],\n",
            "        [-0.3447, -0.2632, -0.3317,  ..., -0.0762,  0.2149, -0.2433],\n",
            "        [-0.3447, -0.2632, -0.3317,  ..., -0.0762,  0.2149, -0.2433]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4891, -0.4241, -0.2783,  ...,  0.0750,  0.1281, -0.0441],\n",
            "        [-0.4891, -0.4241, -0.2783,  ...,  0.0750,  0.1281, -0.0441],\n",
            "        [-0.5463, -0.4906, -0.2558,  ...,  0.1369,  0.0915,  0.0335],\n",
            "        ...,\n",
            "        [-0.5168, -0.4387, -0.2791,  ...,  0.0922,  0.1293,  0.0019],\n",
            "        [-0.3426, -0.2603, -0.3314,  ..., -0.0785,  0.2145, -0.2459],\n",
            "        [-0.3426, -0.2603, -0.3314,  ..., -0.0785,  0.2145, -0.2459]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4866, -0.4213, -0.2776,  ...,  0.0724,  0.1277, -0.0471],\n",
            "        [-0.4866, -0.4213, -0.2776,  ...,  0.0724,  0.1277, -0.0471],\n",
            "        [-0.5437, -0.4879, -0.2549,  ...,  0.1341,  0.0911,  0.0305],\n",
            "        ...,\n",
            "        [-0.5142, -0.4361, -0.2784,  ...,  0.0895,  0.1290, -0.0012],\n",
            "        [-0.3405, -0.2575, -0.3311,  ..., -0.0807,  0.2141, -0.2486],\n",
            "        [-0.3405, -0.2575, -0.3311,  ..., -0.0807,  0.2141, -0.2486]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4840, -0.4185, -0.2769,  ...,  0.0698,  0.1273, -0.0501],\n",
            "        [-0.4840, -0.4185, -0.2769,  ...,  0.0698,  0.1273, -0.0501],\n",
            "        [-0.5411, -0.4852, -0.2541,  ...,  0.1314,  0.0907,  0.0274],\n",
            "        ...,\n",
            "        [-0.5116, -0.4334, -0.2776,  ...,  0.0868,  0.1287, -0.0043],\n",
            "        [-0.3383, -0.2547, -0.3309,  ..., -0.0829,  0.2136, -0.2512],\n",
            "        [-0.3383, -0.2547, -0.3309,  ..., -0.0829,  0.2136, -0.2512]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4816, -0.4158, -0.2762,  ...,  0.0672,  0.1269, -0.0532],\n",
            "        [-0.4816, -0.4158, -0.2762,  ...,  0.0672,  0.1269, -0.0532],\n",
            "        [-0.5386, -0.4825, -0.2532,  ...,  0.1288,  0.0903,  0.0244],\n",
            "        ...,\n",
            "        [-0.5090, -0.4307, -0.2769,  ...,  0.0841,  0.1284, -0.0074],\n",
            "        [-0.3362, -0.2519, -0.3306,  ..., -0.0851,  0.2132, -0.2539],\n",
            "        [-0.3362, -0.2519, -0.3306,  ..., -0.0851,  0.2132, -0.2539]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4791, -0.4130, -0.2756,  ...,  0.0646,  0.1264, -0.0562],\n",
            "        [-0.4791, -0.4130, -0.2756,  ...,  0.0646,  0.1264, -0.0562],\n",
            "        [-0.5361, -0.4798, -0.2524,  ...,  0.1261,  0.0899,  0.0215],\n",
            "        ...,\n",
            "        [-0.5064, -0.4281, -0.2762,  ...,  0.0814,  0.1281, -0.0105],\n",
            "        [-0.3341, -0.2491, -0.3303,  ..., -0.0874,  0.2128, -0.2565],\n",
            "        [-0.3341, -0.2491, -0.3303,  ..., -0.0874,  0.2128, -0.2565]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4766, -0.4103, -0.2749,  ...,  0.0620,  0.1260, -0.0591],\n",
            "        [-0.4766, -0.4103, -0.2749,  ...,  0.0620,  0.1260, -0.0591],\n",
            "        [-0.5336, -0.4772, -0.2516,  ...,  0.1234,  0.0895,  0.0185],\n",
            "        ...,\n",
            "        [-0.5039, -0.4254, -0.2755,  ...,  0.0787,  0.1279, -0.0136],\n",
            "        [-0.3320, -0.2463, -0.3301,  ..., -0.0896,  0.2123, -0.2591],\n",
            "        [-0.3320, -0.2463, -0.3301,  ..., -0.0896,  0.2123, -0.2591]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4741, -0.4076, -0.2743,  ...,  0.0595,  0.1256, -0.0621],\n",
            "        [-0.4741, -0.4076, -0.2743,  ...,  0.0595,  0.1256, -0.0621],\n",
            "        [-0.5311, -0.4745, -0.2508,  ...,  0.1208,  0.0891,  0.0156],\n",
            "        ...,\n",
            "        [-0.5014, -0.4228, -0.2748,  ...,  0.0761,  0.1276, -0.0166],\n",
            "        [-0.3299, -0.2434, -0.3298,  ..., -0.0918,  0.2119, -0.2617],\n",
            "        [-0.3299, -0.2434, -0.3298,  ..., -0.0918,  0.2119, -0.2617]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4717, -0.4048, -0.2736,  ...,  0.0569,  0.1252, -0.0651],\n",
            "        [-0.4717, -0.4048, -0.2736,  ...,  0.0569,  0.1252, -0.0651],\n",
            "        [-0.5286, -0.4719, -0.2500,  ...,  0.1182,  0.0886,  0.0127],\n",
            "        ...,\n",
            "        [-0.4988, -0.4201, -0.2741,  ...,  0.0735,  0.1273, -0.0197],\n",
            "        [-0.3278, -0.2406, -0.3296,  ..., -0.0939,  0.2114, -0.2643],\n",
            "        [-0.3278, -0.2406, -0.3296,  ..., -0.0939,  0.2114, -0.2643]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4693, -0.4021, -0.2730,  ...,  0.0544,  0.1248, -0.0680],\n",
            "        [-0.4693, -0.4021, -0.2730,  ...,  0.0544,  0.1248, -0.0680],\n",
            "        [-0.5262, -0.4693, -0.2492,  ...,  0.1156,  0.0882,  0.0098],\n",
            "        ...,\n",
            "        [-0.4963, -0.4175, -0.2734,  ...,  0.0708,  0.1270, -0.0227],\n",
            "        [-0.3257, -0.2378, -0.3293,  ..., -0.0961,  0.2110, -0.2669],\n",
            "        [-0.3257, -0.2378, -0.3293,  ..., -0.0961,  0.2110, -0.2669]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4668, -0.3994, -0.2723,  ...,  0.0518,  0.1244, -0.0709],\n",
            "        [-0.4668, -0.3994, -0.2723,  ...,  0.0518,  0.1244, -0.0709],\n",
            "        [-0.5238, -0.4667, -0.2484,  ...,  0.1130,  0.0878,  0.0070],\n",
            "        ...,\n",
            "        [-0.4938, -0.4148, -0.2727,  ...,  0.0682,  0.1267, -0.0258],\n",
            "        [-0.3236, -0.2350, -0.3291,  ..., -0.0983,  0.2105, -0.2694],\n",
            "        [-0.3236, -0.2350, -0.3291,  ..., -0.0983,  0.2105, -0.2694]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4644, -0.3966, -0.2717,  ...,  0.0493,  0.1239, -0.0739],\n",
            "        [-0.4644, -0.3966, -0.2717,  ...,  0.0493,  0.1239, -0.0739],\n",
            "        [-0.5214, -0.4641, -0.2476,  ...,  0.1105,  0.0874,  0.0042],\n",
            "        ...,\n",
            "        [-0.4913, -0.4122, -0.2720,  ...,  0.0656,  0.1264, -0.0288],\n",
            "        [-0.3216, -0.2322, -0.3288,  ..., -0.1005,  0.2100, -0.2720],\n",
            "        [-0.3216, -0.2322, -0.3288,  ..., -0.1005,  0.2100, -0.2720]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4620, -0.3939, -0.2711,  ...,  0.0468,  0.1235, -0.0768],\n",
            "        [-0.4620, -0.3939, -0.2711,  ...,  0.0468,  0.1235, -0.0768],\n",
            "        [-0.5190, -0.4615, -0.2469,  ...,  0.1079,  0.0870,  0.0014],\n",
            "        ...,\n",
            "        [-0.4889, -0.4096, -0.2713,  ...,  0.0630,  0.1261, -0.0318],\n",
            "        [-0.3195, -0.2293, -0.3286,  ..., -0.1026,  0.2096, -0.2745],\n",
            "        [-0.3195, -0.2293, -0.3286,  ..., -0.1026,  0.2096, -0.2745]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4597, -0.3912, -0.2705,  ...,  0.0443,  0.1231, -0.0797],\n",
            "        [-0.4597, -0.3912, -0.2705,  ...,  0.0443,  0.1231, -0.0797],\n",
            "        [-0.5167, -0.4589, -0.2461,  ...,  0.1054,  0.0865, -0.0013],\n",
            "        ...,\n",
            "        [-0.4864, -0.4069, -0.2707,  ...,  0.0604,  0.1258, -0.0347],\n",
            "        [-0.3174, -0.2265, -0.3283,  ..., -0.1048,  0.2091, -0.2771],\n",
            "        [-0.3174, -0.2265, -0.3283,  ..., -0.1048,  0.2091, -0.2771]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4573, -0.3885, -0.2699,  ...,  0.0419,  0.1226, -0.0825],\n",
            "        [-0.4573, -0.3885, -0.2699,  ...,  0.0419,  0.1226, -0.0825],\n",
            "        [-0.5144, -0.4564, -0.2453,  ...,  0.1029,  0.0861, -0.0040],\n",
            "        ...,\n",
            "        [-0.4840, -0.4043, -0.2700,  ...,  0.0579,  0.1255, -0.0377],\n",
            "        [-0.3154, -0.2237, -0.3281,  ..., -0.1069,  0.2086, -0.2796],\n",
            "        [-0.3154, -0.2237, -0.3281,  ..., -0.1069,  0.2086, -0.2796]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4550, -0.3858, -0.2693,  ...,  0.0394,  0.1222, -0.0854],\n",
            "        [-0.4550, -0.3858, -0.2693,  ...,  0.0394,  0.1222, -0.0854],\n",
            "        [-0.5121, -0.4538, -0.2446,  ...,  0.1005,  0.0857, -0.0067],\n",
            "        ...,\n",
            "        [-0.4815, -0.4017, -0.2694,  ...,  0.0553,  0.1252, -0.0407],\n",
            "        [-0.3134, -0.2209, -0.3278,  ..., -0.1091,  0.2081, -0.2821],\n",
            "        [-0.3134, -0.2209, -0.3278,  ..., -0.1091,  0.2081, -0.2821]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4526, -0.3831, -0.2687,  ...,  0.0369,  0.1218, -0.0883],\n",
            "        [-0.4526, -0.3831, -0.2687,  ...,  0.0369,  0.1218, -0.0883],\n",
            "        [-0.5099, -0.4513, -0.2438,  ...,  0.0980,  0.0852, -0.0094],\n",
            "        ...,\n",
            "        [-0.4791, -0.3990, -0.2687,  ...,  0.0527,  0.1249, -0.0436],\n",
            "        [-0.3113, -0.2180, -0.3276,  ..., -0.1112,  0.2077, -0.2847],\n",
            "        [-0.3113, -0.2180, -0.3276,  ..., -0.1112,  0.2077, -0.2847]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4503, -0.3804, -0.2681,  ...,  0.0345,  0.1213, -0.0911],\n",
            "        [-0.4503, -0.3804, -0.2681,  ...,  0.0345,  0.1213, -0.0911],\n",
            "        [-0.5076, -0.4488, -0.2430,  ...,  0.0956,  0.0848, -0.0120],\n",
            "        ...,\n",
            "        [-0.4767, -0.3964, -0.2681,  ...,  0.0502,  0.1246, -0.0466],\n",
            "        [-0.3093, -0.2152, -0.3274,  ..., -0.1133,  0.2072, -0.2872],\n",
            "        [-0.3093, -0.2152, -0.3274,  ..., -0.1133,  0.2072, -0.2872]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4480, -0.3777, -0.2675,  ...,  0.0320,  0.1209, -0.0939],\n",
            "        [-0.4480, -0.3777, -0.2675,  ...,  0.0320,  0.1209, -0.0939],\n",
            "        [-0.5054, -0.4463, -0.2423,  ...,  0.0932,  0.0844, -0.0145],\n",
            "        ...,\n",
            "        [-0.4743, -0.3938, -0.2675,  ...,  0.0477,  0.1243, -0.0495],\n",
            "        [-0.3073, -0.2124, -0.3271,  ..., -0.1154,  0.2067, -0.2897],\n",
            "        [-0.3073, -0.2124, -0.3271,  ..., -0.1154,  0.2067, -0.2897]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4457, -0.3750, -0.2669,  ...,  0.0296,  0.1204, -0.0968],\n",
            "        [-0.4457, -0.3750, -0.2669,  ...,  0.0296,  0.1204, -0.0968],\n",
            "        [-0.5033, -0.4438, -0.2415,  ...,  0.0908,  0.0839, -0.0171],\n",
            "        ...,\n",
            "        [-0.4720, -0.3912, -0.2669,  ...,  0.0452,  0.1240, -0.0524],\n",
            "        [-0.3053, -0.2095, -0.3269,  ..., -0.1176,  0.2062, -0.2922],\n",
            "        [-0.3053, -0.2095, -0.3269,  ..., -0.1176,  0.2062, -0.2922]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4434, -0.3723, -0.2663,  ...,  0.0272,  0.1199, -0.0996],\n",
            "        [-0.4434, -0.3723, -0.2663,  ...,  0.0272,  0.1199, -0.0996],\n",
            "        [-0.5011, -0.4413, -0.2408,  ...,  0.0884,  0.0835, -0.0196],\n",
            "        ...,\n",
            "        [-0.4696, -0.3885, -0.2663,  ...,  0.0426,  0.1237, -0.0553],\n",
            "        [-0.3033, -0.2067, -0.3267,  ..., -0.1197,  0.2057, -0.2947],\n",
            "        [-0.3033, -0.2067, -0.3267,  ..., -0.1197,  0.2057, -0.2947]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4411, -0.3696, -0.2657,  ...,  0.0248,  0.1195, -0.1023],\n",
            "        [-0.4411, -0.3696, -0.2657,  ...,  0.0248,  0.1195, -0.1023],\n",
            "        [-0.4990, -0.4389, -0.2401,  ...,  0.0861,  0.0831, -0.0221],\n",
            "        ...,\n",
            "        [-0.4672, -0.3859, -0.2656,  ...,  0.0402,  0.1233, -0.0582],\n",
            "        [-0.3014, -0.2039, -0.3264,  ..., -0.1218,  0.2052, -0.2971],\n",
            "        [-0.3014, -0.2039, -0.3264,  ..., -0.1218,  0.2052, -0.2971]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4389, -0.3669, -0.2651,  ...,  0.0224,  0.1190, -0.1051],\n",
            "        [-0.4389, -0.3669, -0.2651,  ...,  0.0224,  0.1190, -0.1051],\n",
            "        [-0.4969, -0.4365, -0.2393,  ...,  0.0837,  0.0826, -0.0245],\n",
            "        ...,\n",
            "        [-0.4649, -0.3833, -0.2651,  ...,  0.0377,  0.1230, -0.0611],\n",
            "        [-0.2994, -0.2010, -0.3262,  ..., -0.1239,  0.2046, -0.2996],\n",
            "        [-0.2994, -0.2010, -0.3262,  ..., -0.1239,  0.2046, -0.2996]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4366, -0.3642, -0.2646,  ...,  0.0200,  0.1185, -0.1079],\n",
            "        [-0.4366, -0.3642, -0.2646,  ...,  0.0200,  0.1185, -0.1079],\n",
            "        [-0.4948, -0.4341, -0.2386,  ...,  0.0814,  0.0822, -0.0269],\n",
            "        ...,\n",
            "        [-0.4626, -0.3807, -0.2645,  ...,  0.0352,  0.1227, -0.0639],\n",
            "        [-0.2974, -0.1982, -0.3260,  ..., -0.1259,  0.2041, -0.3021],\n",
            "        [-0.2974, -0.1982, -0.3260,  ..., -0.1259,  0.2041, -0.3021]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4344, -0.3616, -0.2640,  ...,  0.0177,  0.1180, -0.1106],\n",
            "        [-0.4344, -0.3616, -0.2640,  ...,  0.0177,  0.1180, -0.1106],\n",
            "        [-0.4928, -0.4317, -0.2379,  ...,  0.0791,  0.0817, -0.0293],\n",
            "        ...,\n",
            "        [-0.4603, -0.3781, -0.2639,  ...,  0.0327,  0.1224, -0.0668],\n",
            "        [-0.2955, -0.1954, -0.3257,  ..., -0.1280,  0.2036, -0.3045],\n",
            "        [-0.2955, -0.1954, -0.3257,  ..., -0.1280,  0.2036, -0.3045]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4322, -0.3589, -0.2634,  ...,  0.0153,  0.1176, -0.1134],\n",
            "        [-0.4322, -0.3589, -0.2634,  ...,  0.0153,  0.1176, -0.1134],\n",
            "        [-0.4908, -0.4293, -0.2371,  ...,  0.0769,  0.0813, -0.0316],\n",
            "        ...,\n",
            "        [-0.4580, -0.3755, -0.2633,  ...,  0.0303,  0.1221, -0.0696],\n",
            "        [-0.2935, -0.1925, -0.3255,  ..., -0.1301,  0.2031, -0.3069],\n",
            "        [-0.2935, -0.1925, -0.3255,  ..., -0.1301,  0.2031, -0.3069]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4300, -0.3562, -0.2629,  ...,  0.0130,  0.1171, -0.1161],\n",
            "        [-0.4300, -0.3562, -0.2629,  ...,  0.0130,  0.1171, -0.1161],\n",
            "        [-0.4888, -0.4269, -0.2364,  ...,  0.0746,  0.0808, -0.0340],\n",
            "        ...,\n",
            "        [-0.4557, -0.3729, -0.2627,  ...,  0.0278,  0.1217, -0.0725],\n",
            "        [-0.2916, -0.1897, -0.3253,  ..., -0.1322,  0.2025, -0.3094],\n",
            "        [-0.2916, -0.1897, -0.3253,  ..., -0.1322,  0.2025, -0.3094]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4278, -0.3536, -0.2623,  ...,  0.0106,  0.1166, -0.1188],\n",
            "        [-0.4278, -0.3536, -0.2623,  ...,  0.0106,  0.1166, -0.1188],\n",
            "        [-0.4868, -0.4246, -0.2357,  ...,  0.0724,  0.0804, -0.0362],\n",
            "        ...,\n",
            "        [-0.4534, -0.3703, -0.2622,  ...,  0.0254,  0.1214, -0.0753],\n",
            "        [-0.2896, -0.1869, -0.3250,  ..., -0.1343,  0.2020, -0.3118],\n",
            "        [-0.2896, -0.1869, -0.3250,  ..., -0.1343,  0.2020, -0.3118]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4256, -0.3509, -0.2618,  ...,  0.0083,  0.1161, -0.1215],\n",
            "        [-0.4256, -0.3509, -0.2618,  ...,  0.0083,  0.1161, -0.1215],\n",
            "        [-0.4849, -0.4222, -0.2350,  ...,  0.0702,  0.0800, -0.0385],\n",
            "        ...,\n",
            "        [-0.4511, -0.3677, -0.2616,  ...,  0.0230,  0.1211, -0.0781],\n",
            "        [-0.2877, -0.1840, -0.3248,  ..., -0.1363,  0.2014, -0.3142],\n",
            "        [-0.2877, -0.1840, -0.3248,  ..., -0.1363,  0.2014, -0.3142]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4234, -0.3482, -0.2612,  ...,  0.0060,  0.1156, -0.1242],\n",
            "        [-0.4234, -0.3482, -0.2612,  ...,  0.0060,  0.1156, -0.1242],\n",
            "        [-0.4829, -0.4199, -0.2343,  ...,  0.0680,  0.0795, -0.0407],\n",
            "        ...,\n",
            "        [-0.4489, -0.3651, -0.2610,  ...,  0.0205,  0.1207, -0.0809],\n",
            "        [-0.2858, -0.1812, -0.3245,  ..., -0.1384,  0.2009, -0.3166],\n",
            "        [-0.2858, -0.1812, -0.3245,  ..., -0.1384,  0.2009, -0.3166]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4213, -0.3456, -0.2606,  ...,  0.0037,  0.1150, -0.1269],\n",
            "        [-0.4213, -0.3456, -0.2606,  ...,  0.0037,  0.1150, -0.1269],\n",
            "        [-0.4810, -0.4176, -0.2336,  ...,  0.0658,  0.0791, -0.0429],\n",
            "        ...,\n",
            "        [-0.4467, -0.3625, -0.2605,  ...,  0.0181,  0.1204, -0.0837],\n",
            "        [-0.2839, -0.1783, -0.3243,  ..., -0.1404,  0.2003, -0.3190],\n",
            "        [-0.2839, -0.1783, -0.3243,  ..., -0.1404,  0.2003, -0.3190]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4191, -0.3429, -0.2601,  ...,  0.0014,  0.1145, -0.1296],\n",
            "        [-0.4191, -0.3429, -0.2601,  ...,  0.0014,  0.1145, -0.1296],\n",
            "        [-0.4792, -0.4153, -0.2328,  ...,  0.0636,  0.0786, -0.0450],\n",
            "        ...,\n",
            "        [-0.4444, -0.3599, -0.2600,  ...,  0.0157,  0.1201, -0.0865],\n",
            "        [-0.2820, -0.1755, -0.3241,  ..., -0.1425,  0.1997, -0.3214],\n",
            "        [-0.2820, -0.1755, -0.3241,  ..., -0.1425,  0.1997, -0.3214]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4170, -0.3403, -0.2595,  ..., -0.0009,  0.1140, -0.1322],\n",
            "        [-0.4170, -0.3403, -0.2595,  ..., -0.0009,  0.1140, -0.1322],\n",
            "        [-0.4773, -0.4131, -0.2321,  ...,  0.0615,  0.0781, -0.0472],\n",
            "        ...,\n",
            "        [-0.4422, -0.3573, -0.2594,  ...,  0.0134,  0.1197, -0.0892],\n",
            "        [-0.2801, -0.1726, -0.3238,  ..., -0.1445,  0.1991, -0.3238],\n",
            "        [-0.2801, -0.1726, -0.3238,  ..., -0.1445,  0.1991, -0.3238]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4149, -0.3376, -0.2590,  ..., -0.0031,  0.1135, -0.1349],\n",
            "        [-0.4149, -0.3376, -0.2590,  ..., -0.0031,  0.1135, -0.1349],\n",
            "        [-0.4755, -0.4108, -0.2314,  ...,  0.0594,  0.0777, -0.0493],\n",
            "        ...,\n",
            "        [-0.4400, -0.3547, -0.2589,  ...,  0.0110,  0.1194, -0.0920],\n",
            "        [-0.2783, -0.1697, -0.3235,  ..., -0.1466,  0.1986, -0.3262],\n",
            "        [-0.2783, -0.1697, -0.3235,  ..., -0.1466,  0.1986, -0.3262]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4128, -0.3350, -0.2584,  ..., -0.0054,  0.1129, -0.1375],\n",
            "        [-0.4128, -0.3350, -0.2584,  ..., -0.0054,  0.1129, -0.1375],\n",
            "        [-0.4737, -0.4086, -0.2307,  ...,  0.0573,  0.0772, -0.0513],\n",
            "        ...,\n",
            "        [-0.4378, -0.3521, -0.2583,  ...,  0.0086,  0.1190, -0.0947],\n",
            "        [-0.2764, -0.1669, -0.3233,  ..., -0.1486,  0.1980, -0.3286],\n",
            "        [-0.2764, -0.1669, -0.3233,  ..., -0.1486,  0.1980, -0.3286]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4107, -0.3323, -0.2579,  ..., -0.0077,  0.1124, -0.1401],\n",
            "        [-0.4107, -0.3323, -0.2579,  ..., -0.0077,  0.1124, -0.1401],\n",
            "        [-0.4719, -0.4064, -0.2300,  ...,  0.0552,  0.0768, -0.0534],\n",
            "        ...,\n",
            "        [-0.4357, -0.3495, -0.2578,  ...,  0.0063,  0.1187, -0.0975],\n",
            "        [-0.2746, -0.1640, -0.3230,  ..., -0.1506,  0.1974, -0.3309],\n",
            "        [-0.2746, -0.1640, -0.3230,  ..., -0.1506,  0.1974, -0.3309]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4086, -0.3297, -0.2573,  ..., -0.0099,  0.1118, -0.1427],\n",
            "        [-0.4086, -0.3297, -0.2573,  ..., -0.0099,  0.1118, -0.1427],\n",
            "        [-0.4702, -0.4042, -0.2293,  ...,  0.0531,  0.0763, -0.0554],\n",
            "        ...,\n",
            "        [-0.4335, -0.3469, -0.2573,  ...,  0.0039,  0.1183, -0.1002],\n",
            "        [-0.2727, -0.1612, -0.3228,  ..., -0.1527,  0.1968, -0.3333],\n",
            "        [-0.2727, -0.1612, -0.3228,  ..., -0.1527,  0.1968, -0.3333]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4066, -0.3271, -0.2568,  ..., -0.0121,  0.1113, -0.1453],\n",
            "        [-0.4066, -0.3271, -0.2568,  ..., -0.0121,  0.1113, -0.1453],\n",
            "        [-0.4684, -0.4020, -0.2286,  ...,  0.0510,  0.0759, -0.0574],\n",
            "        ...,\n",
            "        [-0.4313, -0.3443, -0.2568,  ...,  0.0016,  0.1180, -0.1029],\n",
            "        [-0.2709, -0.1583, -0.3225,  ..., -0.1547,  0.1962, -0.3357],\n",
            "        [-0.2709, -0.1583, -0.3225,  ..., -0.1547,  0.1962, -0.3357]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4045, -0.3244, -0.2562,  ..., -0.0144,  0.1107, -0.1479],\n",
            "        [-0.4045, -0.3244, -0.2562,  ..., -0.0144,  0.1107, -0.1479],\n",
            "        [-0.4667, -0.3998, -0.2279,  ...,  0.0490,  0.0754, -0.0594],\n",
            "        ...,\n",
            "        [-0.4292, -0.3417, -0.2563,  ..., -0.0008,  0.1176, -0.1056],\n",
            "        [-0.2691, -0.1554, -0.3222,  ..., -0.1567,  0.1955, -0.3380],\n",
            "        [-0.2691, -0.1554, -0.3222,  ..., -0.1567,  0.1955, -0.3380]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4025, -0.3218, -0.2557,  ..., -0.0166,  0.1102, -0.1505],\n",
            "        [-0.4025, -0.3218, -0.2557,  ..., -0.0166,  0.1102, -0.1505],\n",
            "        [-0.4650, -0.3977, -0.2272,  ...,  0.0470,  0.0750, -0.0613],\n",
            "        ...,\n",
            "        [-0.4271, -0.3391, -0.2558,  ..., -0.0031,  0.1172, -0.1083],\n",
            "        [-0.2673, -0.1526, -0.3219,  ..., -0.1587,  0.1949, -0.3403],\n",
            "        [-0.2673, -0.1526, -0.3219,  ..., -0.1587,  0.1949, -0.3403]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.4005, -0.3192, -0.2552,  ..., -0.0188,  0.1096, -0.1530],\n",
            "        [-0.4005, -0.3192, -0.2552,  ..., -0.0188,  0.1096, -0.1530],\n",
            "        [-0.4633, -0.3955, -0.2265,  ...,  0.0450,  0.0745, -0.0632],\n",
            "        ...,\n",
            "        [-0.4250, -0.3365, -0.2553,  ..., -0.0054,  0.1169, -0.1110],\n",
            "        [-0.2655, -0.1497, -0.3216,  ..., -0.1608,  0.1943, -0.3427],\n",
            "        [-0.2655, -0.1497, -0.3216,  ..., -0.1608,  0.1943, -0.3427]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3985, -0.3166, -0.2546,  ..., -0.0210,  0.1090, -0.1556],\n",
            "        [-0.3985, -0.3166, -0.2546,  ..., -0.0210,  0.1090, -0.1556],\n",
            "        [-0.4617, -0.3934, -0.2259,  ...,  0.0430,  0.0741, -0.0651],\n",
            "        ...,\n",
            "        [-0.4229, -0.3339, -0.2548,  ..., -0.0077,  0.1165, -0.1137],\n",
            "        [-0.2637, -0.1468, -0.3213,  ..., -0.1628,  0.1937, -0.3450],\n",
            "        [-0.2637, -0.1468, -0.3213,  ..., -0.1628,  0.1937, -0.3450]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3965, -0.3139, -0.2541,  ..., -0.0232,  0.1084, -0.1581],\n",
            "        [-0.3965, -0.3139, -0.2541,  ..., -0.0232,  0.1084, -0.1581],\n",
            "        [-0.4601, -0.3913, -0.2252,  ...,  0.0410,  0.0736, -0.0670],\n",
            "        ...,\n",
            "        [-0.4208, -0.3313, -0.2543,  ..., -0.0100,  0.1161, -0.1163],\n",
            "        [-0.2619, -0.1439, -0.3210,  ..., -0.1648,  0.1930, -0.3473],\n",
            "        [-0.2619, -0.1439, -0.3210,  ..., -0.1648,  0.1930, -0.3473]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3945, -0.3113, -0.2535,  ..., -0.0253,  0.1078, -0.1606],\n",
            "        [-0.3945, -0.3113, -0.2535,  ..., -0.0253,  0.1078, -0.1606],\n",
            "        [-0.4584, -0.3892, -0.2245,  ...,  0.0390,  0.0731, -0.0689],\n",
            "        ...,\n",
            "        [-0.4187, -0.3287, -0.2538,  ..., -0.0123,  0.1158, -0.1190],\n",
            "        [-0.2602, -0.1410, -0.3207,  ..., -0.1668,  0.1924, -0.3496],\n",
            "        [-0.2602, -0.1410, -0.3207,  ..., -0.1668,  0.1924, -0.3496]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3925, -0.3087, -0.2530,  ..., -0.0275,  0.1072, -0.1632],\n",
            "        [-0.3925, -0.3087, -0.2530,  ..., -0.0275,  0.1072, -0.1632],\n",
            "        [-0.4568, -0.3871, -0.2238,  ...,  0.0370,  0.0727, -0.0707],\n",
            "        ...,\n",
            "        [-0.4166, -0.3262, -0.2533,  ..., -0.0146,  0.1154, -0.1217],\n",
            "        [-0.2584, -0.1381, -0.3204,  ..., -0.1688,  0.1917, -0.3519],\n",
            "        [-0.2584, -0.1381, -0.3204,  ..., -0.1688,  0.1917, -0.3519]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3906, -0.3061, -0.2524,  ..., -0.0297,  0.1066, -0.1657],\n",
            "        [-0.3906, -0.3061, -0.2524,  ..., -0.0297,  0.1066, -0.1657],\n",
            "        [-0.4553, -0.3850, -0.2231,  ...,  0.0351,  0.0722, -0.0725],\n",
            "        ...,\n",
            "        [-0.4146, -0.3236, -0.2528,  ..., -0.0169,  0.1150, -0.1243],\n",
            "        [-0.2567, -0.1352, -0.3201,  ..., -0.1708,  0.1911, -0.3542],\n",
            "        [-0.2567, -0.1352, -0.3201,  ..., -0.1708,  0.1911, -0.3542]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3887, -0.3034, -0.2518,  ..., -0.0318,  0.1060, -0.1682],\n",
            "        [-0.3887, -0.3034, -0.2518,  ..., -0.0318,  0.1060, -0.1682],\n",
            "        [-0.4537, -0.3830, -0.2224,  ...,  0.0332,  0.0718, -0.0743],\n",
            "        ...,\n",
            "        [-0.4125, -0.3210, -0.2523,  ..., -0.0191,  0.1146, -0.1269],\n",
            "        [-0.2550, -0.1323, -0.3198,  ..., -0.1728,  0.1904, -0.3565],\n",
            "        [-0.2550, -0.1323, -0.3198,  ..., -0.1728,  0.1904, -0.3565]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3867, -0.3008, -0.2513,  ..., -0.0340,  0.1054, -0.1707],\n",
            "        [-0.3867, -0.3008, -0.2513,  ..., -0.0340,  0.1054, -0.1707],\n",
            "        [-0.4521, -0.3809, -0.2217,  ...,  0.0313,  0.0713, -0.0761],\n",
            "        ...,\n",
            "        [-0.4105, -0.3184, -0.2518,  ..., -0.0214,  0.1142, -0.1295],\n",
            "        [-0.2533, -0.1294, -0.3194,  ..., -0.1748,  0.1897, -0.3588],\n",
            "        [-0.2533, -0.1294, -0.3194,  ..., -0.1748,  0.1897, -0.3588]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3848, -0.2982, -0.2507,  ..., -0.0361,  0.1048, -0.1731],\n",
            "        [-0.3848, -0.2982, -0.2507,  ..., -0.0361,  0.1048, -0.1731],\n",
            "        [-0.4506, -0.3789, -0.2211,  ...,  0.0294,  0.0709, -0.0779],\n",
            "        ...,\n",
            "        [-0.4085, -0.3158, -0.2514,  ..., -0.0237,  0.1138, -0.1322],\n",
            "        [-0.2516, -0.1265, -0.3191,  ..., -0.1768,  0.1890, -0.3611],\n",
            "        [-0.2516, -0.1265, -0.3191,  ..., -0.1768,  0.1890, -0.3611]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3829, -0.2956, -0.2502,  ..., -0.0382,  0.1041, -0.1756],\n",
            "        [-0.3829, -0.2956, -0.2502,  ..., -0.0382,  0.1041, -0.1756],\n",
            "        [-0.4491, -0.3768, -0.2204,  ...,  0.0275,  0.0704, -0.0796],\n",
            "        ...,\n",
            "        [-0.4065, -0.3132, -0.2509,  ..., -0.0259,  0.1134, -0.1348],\n",
            "        [-0.2499, -0.1236, -0.3187,  ..., -0.1788,  0.1883, -0.3633],\n",
            "        [-0.2499, -0.1236, -0.3187,  ..., -0.1788,  0.1883, -0.3633]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3811, -0.2930, -0.2496,  ..., -0.0404,  0.1035, -0.1781],\n",
            "        [-0.3811, -0.2930, -0.2496,  ..., -0.0404,  0.1035, -0.1781],\n",
            "        [-0.4476, -0.3748, -0.2197,  ...,  0.0256,  0.0699, -0.0814],\n",
            "        ...,\n",
            "        [-0.4045, -0.3106, -0.2504,  ..., -0.0281,  0.1130, -0.1373],\n",
            "        [-0.2483, -0.1207, -0.3184,  ..., -0.1808,  0.1876, -0.3656],\n",
            "        [-0.2483, -0.1207, -0.3184,  ..., -0.1808,  0.1876, -0.3656]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3792, -0.2904, -0.2490,  ..., -0.0425,  0.1029, -0.1805],\n",
            "        [-0.3792, -0.2904, -0.2490,  ..., -0.0425,  0.1029, -0.1805],\n",
            "        [-0.4461, -0.3728, -0.2190,  ...,  0.0237,  0.0695, -0.0831],\n",
            "        ...,\n",
            "        [-0.4025, -0.3080, -0.2499,  ..., -0.0304,  0.1126, -0.1399],\n",
            "        [-0.2466, -0.1178, -0.3180,  ..., -0.1828,  0.1869, -0.3678],\n",
            "        [-0.2466, -0.1178, -0.3180,  ..., -0.1828,  0.1869, -0.3678]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3773, -0.2878, -0.2485,  ..., -0.0446,  0.1022, -0.1829],\n",
            "        [-0.3773, -0.2878, -0.2485,  ..., -0.0446,  0.1022, -0.1829],\n",
            "        [-0.4446, -0.3708, -0.2184,  ...,  0.0218,  0.0690, -0.0848],\n",
            "        ...,\n",
            "        [-0.4005, -0.3054, -0.2494,  ..., -0.0326,  0.1122, -0.1425],\n",
            "        [-0.2450, -0.1149, -0.3176,  ..., -0.1848,  0.1862, -0.3701],\n",
            "        [-0.2450, -0.1149, -0.3176,  ..., -0.1848,  0.1862, -0.3701]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3755, -0.2852, -0.2479,  ..., -0.0467,  0.1015, -0.1854],\n",
            "        [-0.3755, -0.2852, -0.2479,  ..., -0.0467,  0.1015, -0.1854],\n",
            "        [-0.4432, -0.3688, -0.2177,  ...,  0.0200,  0.0686, -0.0865],\n",
            "        ...,\n",
            "        [-0.3986, -0.3028, -0.2490,  ..., -0.0348,  0.1118, -0.1451],\n",
            "        [-0.2434, -0.1120, -0.3172,  ..., -0.1868,  0.1855, -0.3723],\n",
            "        [-0.2434, -0.1120, -0.3172,  ..., -0.1868,  0.1855, -0.3723]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3737, -0.2826, -0.2473,  ..., -0.0488,  0.1009, -0.1878],\n",
            "        [-0.3737, -0.2826, -0.2473,  ..., -0.0488,  0.1009, -0.1878],\n",
            "        [-0.4418, -0.3669, -0.2170,  ...,  0.0182,  0.0681, -0.0881],\n",
            "        ...,\n",
            "        [-0.3966, -0.3002, -0.2485,  ..., -0.0370,  0.1113, -0.1476],\n",
            "        [-0.2418, -0.1090, -0.3168,  ..., -0.1887,  0.1848, -0.3746],\n",
            "        [-0.2418, -0.1090, -0.3168,  ..., -0.1887,  0.1848, -0.3746]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3719, -0.2800, -0.2467,  ..., -0.0509,  0.1002, -0.1902],\n",
            "        [-0.3719, -0.2800, -0.2467,  ..., -0.0509,  0.1002, -0.1902],\n",
            "        [-0.4403, -0.3649, -0.2163,  ...,  0.0163,  0.0676, -0.0898],\n",
            "        ...,\n",
            "        [-0.3947, -0.2976, -0.2480,  ..., -0.0392,  0.1109, -0.1502],\n",
            "        [-0.2402, -0.1061, -0.3164,  ..., -0.1907,  0.1840, -0.3768],\n",
            "        [-0.2402, -0.1061, -0.3164,  ..., -0.1907,  0.1840, -0.3768]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3701, -0.2774, -0.2462,  ..., -0.0530,  0.0995, -0.1926],\n",
            "        [-0.3701, -0.2774, -0.2462,  ..., -0.0530,  0.0995, -0.1926],\n",
            "        [-0.4389, -0.3630, -0.2157,  ...,  0.0145,  0.0672, -0.0914],\n",
            "        ...,\n",
            "        [-0.3928, -0.2950, -0.2476,  ..., -0.0414,  0.1105, -0.1527],\n",
            "        [-0.2387, -0.1032, -0.3160,  ..., -0.1927,  0.1833, -0.3790],\n",
            "        [-0.2387, -0.1032, -0.3160,  ..., -0.1927,  0.1833, -0.3790]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3683, -0.2748, -0.2456,  ..., -0.0550,  0.0988, -0.1950],\n",
            "        [-0.3683, -0.2748, -0.2456,  ..., -0.0550,  0.0988, -0.1950],\n",
            "        [-0.4375, -0.3610, -0.2150,  ...,  0.0127,  0.0667, -0.0931],\n",
            "        ...,\n",
            "        [-0.3909, -0.2924, -0.2471,  ..., -0.0436,  0.1100, -0.1553],\n",
            "        [-0.2371, -0.1002, -0.3156,  ..., -0.1947,  0.1825, -0.3813],\n",
            "        [-0.2371, -0.1002, -0.3156,  ..., -0.1947,  0.1825, -0.3813]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3666, -0.2722, -0.2450,  ..., -0.0571,  0.0981, -0.1974],\n",
            "        [-0.3666, -0.2722, -0.2450,  ..., -0.0571,  0.0981, -0.1974],\n",
            "        [-0.4361, -0.3591, -0.2143,  ...,  0.0109,  0.0663, -0.0947],\n",
            "        ...,\n",
            "        [-0.3890, -0.2898, -0.2466,  ..., -0.0458,  0.1096, -0.1578],\n",
            "        [-0.2356, -0.0973, -0.3152,  ..., -0.1967,  0.1818, -0.3835],\n",
            "        [-0.2356, -0.0973, -0.3152,  ..., -0.1967,  0.1818, -0.3835]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3648, -0.2695, -0.2444,  ..., -0.0592,  0.0974, -0.1997],\n",
            "        [-0.3648, -0.2695, -0.2444,  ..., -0.0592,  0.0974, -0.1997],\n",
            "        [-0.4348, -0.3572, -0.2137,  ...,  0.0091,  0.0658, -0.0963],\n",
            "        ...,\n",
            "        [-0.3871, -0.2872, -0.2462,  ..., -0.0480,  0.1092, -0.1603],\n",
            "        [-0.2341, -0.0943, -0.3147,  ..., -0.1987,  0.1810, -0.3857],\n",
            "        [-0.2341, -0.0943, -0.3147,  ..., -0.1987,  0.1810, -0.3857]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3631, -0.2669, -0.2438,  ..., -0.0612,  0.0967, -0.2021],\n",
            "        [-0.3631, -0.2669, -0.2438,  ..., -0.0612,  0.0967, -0.2021],\n",
            "        [-0.4334, -0.3553, -0.2130,  ...,  0.0073,  0.0653, -0.0979],\n",
            "        ...,\n",
            "        [-0.3852, -0.2846, -0.2457,  ..., -0.0502,  0.1087, -0.1628],\n",
            "        [-0.2326, -0.0913, -0.3142,  ..., -0.2007,  0.1802, -0.3879],\n",
            "        [-0.2326, -0.0913, -0.3142,  ..., -0.2007,  0.1802, -0.3879]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3614, -0.2643, -0.2432,  ..., -0.0633,  0.0960, -0.2044],\n",
            "        [-0.3614, -0.2643, -0.2432,  ..., -0.0633,  0.0960, -0.2044],\n",
            "        [-0.4321, -0.3534, -0.2123,  ...,  0.0056,  0.0649, -0.0995],\n",
            "        ...,\n",
            "        [-0.3834, -0.2820, -0.2452,  ..., -0.0524,  0.1083, -0.1653],\n",
            "        [-0.2311, -0.0884, -0.3138,  ..., -0.2027,  0.1794, -0.3901],\n",
            "        [-0.2311, -0.0884, -0.3138,  ..., -0.2027,  0.1794, -0.3901]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3597, -0.2617, -0.2425,  ..., -0.0653,  0.0953, -0.2068],\n",
            "        [-0.3597, -0.2617, -0.2425,  ..., -0.0653,  0.0953, -0.2068],\n",
            "        [-0.4307, -0.3515, -0.2117,  ...,  0.0038,  0.0644, -0.1011],\n",
            "        ...,\n",
            "        [-0.3815, -0.2794, -0.2447,  ..., -0.0545,  0.1078, -0.1678],\n",
            "        [-0.2297, -0.0854, -0.3133,  ..., -0.2047,  0.1786, -0.3923],\n",
            "        [-0.2297, -0.0854, -0.3133,  ..., -0.2047,  0.1786, -0.3923]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3580, -0.2591, -0.2419,  ..., -0.0674,  0.0945, -0.2091],\n",
            "        [-0.3580, -0.2591, -0.2419,  ..., -0.0674,  0.0945, -0.2091],\n",
            "        [-0.4294, -0.3496, -0.2110,  ...,  0.0021,  0.0639, -0.1027],\n",
            "        ...,\n",
            "        [-0.3797, -0.2768, -0.2443,  ..., -0.0567,  0.1073, -0.1703],\n",
            "        [-0.2282, -0.0824, -0.3128,  ..., -0.2067,  0.1778, -0.3945],\n",
            "        [-0.2282, -0.0824, -0.3128,  ..., -0.2067,  0.1778, -0.3945]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-3.5635e-01, -2.5654e-01, -2.4129e-01,  ..., -6.9408e-02,\n",
            "          9.3775e-02, -2.1143e-01],\n",
            "        [-3.5635e-01, -2.5654e-01, -2.4129e-01,  ..., -6.9408e-02,\n",
            "          9.3775e-02, -2.1143e-01],\n",
            "        [-4.2808e-01, -3.4768e-01, -2.1036e-01,  ...,  3.1880e-04,\n",
            "          6.3472e-02, -1.0425e-01],\n",
            "        ...,\n",
            "        [-3.7788e-01, -2.7417e-01, -2.4380e-01,  ..., -5.8868e-02,\n",
            "          1.0686e-01, -1.7280e-01],\n",
            "        [-2.2681e-01, -7.9456e-02, -3.1229e-01,  ..., -2.0867e-01,\n",
            "          1.7703e-01, -3.9668e-01],\n",
            "        [-2.2681e-01, -7.9456e-02, -3.1229e-01,  ..., -2.0867e-01,\n",
            "          1.7703e-01, -3.9668e-01]], grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3547, -0.2539, -0.2407,  ..., -0.0714,  0.0930, -0.2137],\n",
            "        [-0.3547, -0.2539, -0.2407,  ..., -0.0714,  0.0930, -0.2137],\n",
            "        [-0.4268, -0.3458, -0.2097,  ..., -0.0014,  0.0630, -0.1058],\n",
            "        ...,\n",
            "        [-0.3761, -0.2716, -0.2433,  ..., -0.0610,  0.1064, -0.1753],\n",
            "        [-0.2254, -0.0765, -0.3118,  ..., -0.2107,  0.1762, -0.3989],\n",
            "        [-0.2254, -0.0765, -0.3118,  ..., -0.2107,  0.1762, -0.3989]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3531, -0.2513, -0.2400,  ..., -0.0735,  0.0923, -0.2161],\n",
            "        [-0.3531, -0.2513, -0.2400,  ..., -0.0735,  0.0923, -0.2161],\n",
            "        [-0.4255, -0.3439, -0.2090,  ..., -0.0031,  0.0625, -0.1074],\n",
            "        ...,\n",
            "        [-0.3743, -0.2689, -0.2428,  ..., -0.0632,  0.1059, -0.1777],\n",
            "        [-0.2240, -0.0735, -0.3112,  ..., -0.2127,  0.1754, -0.4010],\n",
            "        [-0.2240, -0.0735, -0.3112,  ..., -0.2127,  0.1754, -0.4010]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3515, -0.2487, -0.2394,  ..., -0.0755,  0.0915, -0.2184],\n",
            "        [-0.3515, -0.2487, -0.2394,  ..., -0.0755,  0.0915, -0.2184],\n",
            "        [-0.4242, -0.3421, -0.2084,  ..., -0.0049,  0.0621, -0.1089],\n",
            "        ...,\n",
            "        [-0.3725, -0.2663, -0.2424,  ..., -0.0653,  0.1054, -0.1802],\n",
            "        [-0.2227, -0.0705, -0.3107,  ..., -0.2147,  0.1745, -0.4032],\n",
            "        [-0.2227, -0.0705, -0.3107,  ..., -0.2147,  0.1745, -0.4032]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3499, -0.2461, -0.2387,  ..., -0.0775,  0.0907, -0.2206],\n",
            "        [-0.3499, -0.2461, -0.2387,  ..., -0.0775,  0.0907, -0.2206],\n",
            "        [-0.4229, -0.3402, -0.2077,  ..., -0.0066,  0.0616, -0.1104],\n",
            "        ...,\n",
            "        [-0.3708, -0.2637, -0.2419,  ..., -0.0675,  0.1049, -0.1827],\n",
            "        [-0.2213, -0.0675, -0.3101,  ..., -0.2167,  0.1737, -0.4054],\n",
            "        [-0.2213, -0.0675, -0.3101,  ..., -0.2167,  0.1737, -0.4054]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3483, -0.2435, -0.2381,  ..., -0.0795,  0.0899, -0.2229],\n",
            "        [-0.3483, -0.2435, -0.2381,  ..., -0.0795,  0.0899, -0.2229],\n",
            "        [-0.4217, -0.3384, -0.2071,  ..., -0.0083,  0.0611, -0.1120],\n",
            "        ...,\n",
            "        [-0.3690, -0.2611, -0.2414,  ..., -0.0696,  0.1045, -0.1851],\n",
            "        [-0.2200, -0.0645, -0.3096,  ..., -0.2187,  0.1729, -0.4075],\n",
            "        [-0.2200, -0.0645, -0.3096,  ..., -0.2187,  0.1729, -0.4075]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3467, -0.2409, -0.2374,  ..., -0.0815,  0.0891, -0.2252],\n",
            "        [-0.3467, -0.2409, -0.2374,  ..., -0.0815,  0.0891, -0.2252],\n",
            "        [-0.4204, -0.3365, -0.2064,  ..., -0.0100,  0.0607, -0.1135],\n",
            "        ...,\n",
            "        [-0.3673, -0.2584, -0.2409,  ..., -0.0717,  0.1040, -0.1876],\n",
            "        [-0.2187, -0.0614, -0.3090,  ..., -0.2207,  0.1720, -0.4097],\n",
            "        [-0.2187, -0.0614, -0.3090,  ..., -0.2207,  0.1720, -0.4097]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3452, -0.2383, -0.2367,  ..., -0.0835,  0.0883, -0.2275],\n",
            "        [-0.3452, -0.2383, -0.2367,  ..., -0.0835,  0.0883, -0.2275],\n",
            "        [-0.4192, -0.3347, -0.2058,  ..., -0.0117,  0.0602, -0.1150],\n",
            "        ...,\n",
            "        [-0.3656, -0.2558, -0.2404,  ..., -0.0739,  0.1034, -0.1900],\n",
            "        [-0.2175, -0.0584, -0.3084,  ..., -0.2227,  0.1711, -0.4118],\n",
            "        [-0.2175, -0.0584, -0.3084,  ..., -0.2227,  0.1711, -0.4118]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3437, -0.2357, -0.2360,  ..., -0.0856,  0.0875, -0.2297],\n",
            "        [-0.3437, -0.2357, -0.2360,  ..., -0.0856,  0.0875, -0.2297],\n",
            "        [-0.4180, -0.3329, -0.2051,  ..., -0.0134,  0.0597, -0.1165],\n",
            "        ...,\n",
            "        [-0.3639, -0.2532, -0.2399,  ..., -0.0760,  0.1029, -0.1924],\n",
            "        [-0.2162, -0.0554, -0.3078,  ..., -0.2247,  0.1703, -0.4140],\n",
            "        [-0.2162, -0.0554, -0.3078,  ..., -0.2247,  0.1703, -0.4140]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3422, -0.2331, -0.2353,  ..., -0.0876,  0.0867, -0.2320],\n",
            "        [-0.3422, -0.2331, -0.2353,  ..., -0.0876,  0.0867, -0.2320],\n",
            "        [-0.4168, -0.3311, -0.2045,  ..., -0.0150,  0.0592, -0.1180],\n",
            "        ...,\n",
            "        [-0.3622, -0.2505, -0.2394,  ..., -0.0781,  0.1024, -0.1948],\n",
            "        [-0.2150, -0.0524, -0.3072,  ..., -0.2268,  0.1694, -0.4161],\n",
            "        [-0.2150, -0.0524, -0.3072,  ..., -0.2268,  0.1694, -0.4161]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3407, -0.2305, -0.2346,  ..., -0.0896,  0.0859, -0.2342],\n",
            "        [-0.3407, -0.2305, -0.2346,  ..., -0.0896,  0.0859, -0.2342],\n",
            "        [-0.4156, -0.3292, -0.2038,  ..., -0.0167,  0.0588, -0.1195],\n",
            "        ...,\n",
            "        [-0.3605, -0.2479, -0.2389,  ..., -0.0802,  0.1019, -0.1972],\n",
            "        [-0.2138, -0.0493, -0.3065,  ..., -0.2288,  0.1685, -0.4183],\n",
            "        [-0.2138, -0.0493, -0.3065,  ..., -0.2288,  0.1685, -0.4183]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3392, -0.2279, -0.2339,  ..., -0.0916,  0.0851, -0.2365],\n",
            "        [-0.3392, -0.2279, -0.2339,  ..., -0.0916,  0.0851, -0.2365],\n",
            "        [-0.4144, -0.3274, -0.2032,  ..., -0.0184,  0.0583, -0.1210],\n",
            "        ...,\n",
            "        [-0.3589, -0.2453, -0.2384,  ..., -0.0824,  0.1014, -0.1997],\n",
            "        [-0.2126, -0.0463, -0.3059,  ..., -0.2308,  0.1676, -0.4204],\n",
            "        [-0.2126, -0.0463, -0.3059,  ..., -0.2308,  0.1676, -0.4204]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3377, -0.2253, -0.2332,  ..., -0.0936,  0.0842, -0.2387],\n",
            "        [-0.3377, -0.2253, -0.2332,  ..., -0.0936,  0.0842, -0.2387],\n",
            "        [-0.4132, -0.3256, -0.2025,  ..., -0.0200,  0.0578, -0.1225],\n",
            "        ...,\n",
            "        [-0.3573, -0.2426, -0.2379,  ..., -0.0845,  0.1009, -0.2021],\n",
            "        [-0.2114, -0.0432, -0.3052,  ..., -0.2328,  0.1667, -0.4225],\n",
            "        [-0.2114, -0.0432, -0.3052,  ..., -0.2328,  0.1667, -0.4225]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3363, -0.2227, -0.2325,  ..., -0.0955,  0.0834, -0.2409],\n",
            "        [-0.3363, -0.2227, -0.2325,  ..., -0.0955,  0.0834, -0.2409],\n",
            "        [-0.4120, -0.3238, -0.2019,  ..., -0.0217,  0.0573, -0.1240],\n",
            "        ...,\n",
            "        [-0.3556, -0.2400, -0.2374,  ..., -0.0866,  0.1003, -0.2044],\n",
            "        [-0.2103, -0.0401, -0.3045,  ..., -0.2349,  0.1657, -0.4247],\n",
            "        [-0.2103, -0.0401, -0.3045,  ..., -0.2349,  0.1657, -0.4247]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3349, -0.2200, -0.2318,  ..., -0.0975,  0.0825, -0.2431],\n",
            "        [-0.3349, -0.2200, -0.2318,  ..., -0.0975,  0.0825, -0.2431],\n",
            "        [-0.4108, -0.3220, -0.2012,  ..., -0.0233,  0.0568, -0.1255],\n",
            "        ...,\n",
            "        [-0.3540, -0.2373, -0.2369,  ..., -0.0887,  0.0998, -0.2068],\n",
            "        [-0.2091, -0.0371, -0.3039,  ..., -0.2369,  0.1648, -0.4268],\n",
            "        [-0.2091, -0.0371, -0.3039,  ..., -0.2369,  0.1648, -0.4268]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3335, -0.2174, -0.2310,  ..., -0.0995,  0.0816, -0.2453],\n",
            "        [-0.3335, -0.2174, -0.2310,  ..., -0.0995,  0.0816, -0.2453],\n",
            "        [-0.4097, -0.3202, -0.2006,  ..., -0.0250,  0.0563, -0.1270],\n",
            "        ...,\n",
            "        [-0.3524, -0.2347, -0.2364,  ..., -0.0908,  0.0992, -0.2092],\n",
            "        [-0.2080, -0.0340, -0.3032,  ..., -0.2390,  0.1639, -0.4289],\n",
            "        [-0.2080, -0.0340, -0.3032,  ..., -0.2390,  0.1639, -0.4289]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3321, -0.2148, -0.2303,  ..., -0.1015,  0.0808, -0.2475],\n",
            "        [-0.3321, -0.2148, -0.2303,  ..., -0.1015,  0.0808, -0.2475],\n",
            "        [-0.4085, -0.3184, -0.2000,  ..., -0.0266,  0.0559, -0.1284],\n",
            "        ...,\n",
            "        [-0.3509, -0.2320, -0.2359,  ..., -0.0929,  0.0987, -0.2116],\n",
            "        [-0.2070, -0.0309, -0.3024,  ..., -0.2410,  0.1629, -0.4310],\n",
            "        [-0.2070, -0.0309, -0.3024,  ..., -0.2410,  0.1629, -0.4310]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3307, -0.2122, -0.2295,  ..., -0.1035,  0.0799, -0.2497],\n",
            "        [-0.3307, -0.2122, -0.2295,  ..., -0.1035,  0.0799, -0.2497],\n",
            "        [-0.4074, -0.3166, -0.1993,  ..., -0.0283,  0.0554, -0.1299],\n",
            "        ...,\n",
            "        [-0.3493, -0.2293, -0.2354,  ..., -0.0950,  0.0981, -0.2140],\n",
            "        [-0.2059, -0.0278, -0.3017,  ..., -0.2431,  0.1620, -0.4331],\n",
            "        [-0.2059, -0.0278, -0.3017,  ..., -0.2431,  0.1620, -0.4331]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "tensor([[-0.3294, -0.2096, -0.2288,  ..., -0.1055,  0.0790, -0.2519],\n",
            "        [-0.3294, -0.2096, -0.2288,  ..., -0.1055,  0.0790, -0.2519],\n",
            "        [-0.4062, -0.3149, -0.1987,  ..., -0.0299,  0.0549, -0.1314],\n",
            "        ...,\n",
            "        [-0.3478, -0.2267, -0.2348,  ..., -0.0971,  0.0975, -0.2163],\n",
            "        [-0.2049, -0.0247, -0.3010,  ..., -0.2452,  0.1610, -0.4352],\n",
            "        [-0.2049, -0.0247, -0.3010,  ..., -0.2452,  0.1610, -0.4352]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "Epoch  100/100 Cost: 3.087428\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- look-up table 연산 수행"
      ],
      "metadata": {
        "id": "4H6JiaQtBaSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> `model.state_dict()`: 모델의 파라미터와 버퍼를 포함한 모든 가중치를 딕셔너리 형태로 반환\n",
        "- nn.Linear는 weight를 `(out_features,in_features)` 형태로 저장하므로, look-up table 연산을 위해선 transpose 시키고 사용해야함\n",
        "- nn.Linear는 bias를 `(1, out_features)` 형태로 저장"
      ],
      "metadata": {
        "id": "vzkePLHDyaH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# look-up table 연산\n",
        "# print(model.state_dict()['linear1.weight']) # W: (2, output_dim)\n",
        "# print(model.state_dict()['linear1.weight'].T) # W: (output_dim, 2)\n",
        "\n",
        "# print(model.state_dict()['linear2.weight']) # W': (output_dim, 2) <- 행을 바로 읽어오면 됨\n",
        "# print(model.state_dict()['linear2.weight'].T) # W': (2, output_dim)\n",
        "\n",
        "# print(model.state_dict()['linear1.bias']) # b: (2)\n",
        "# print(model.state_dict()['linear2.bias'])   # b': (output_dim)\n",
        "\n",
        "vector = model.state_dict()['linear1.weight'].T\n",
        "# vector = model.state_dict()['linear1.weight'].T + model.state_dict()['linear1.bias'].view(-1,2)\n",
        "# vector = model.state_dict()['linear2.weight'] + model.state_dict()['linear2.bias'].view(-1, 1)\n",
        "w2v_df = pd.DataFrame(vector.numpy(), columns = ['임베딩벡터원소 x1', '임베딩벡터원소 x2'])\n",
        "w2v_df['word'] = vocabulary\n",
        "w2v_df = w2v_df[['word','임베딩벡터원소 x1','임베딩벡터원소 x2']]\n",
        "w2v_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 708
        },
        "id": "aOyV3n6gvrVE",
        "outputId": "9029cf68-f747-4dc6-feb0-f2195a2265a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       word  임베딩벡터원소 x1  임베딩벡터원소 x2\n",
              "0        he    0.043133    0.057207\n",
              "1        is   -0.041558   -0.134948\n",
              "2         a    0.119008    0.122221\n",
              "3      king    0.101386   -0.073457\n",
              "4       she    0.022029    0.019630\n",
              "5     queen   -0.079244    0.236107\n",
              "6       man    0.258880   -0.025212\n",
              "7     woman   -0.011290   -0.102319\n",
              "8    warsaw    0.270881    0.117111\n",
              "9    poland   -0.064048   -0.091271\n",
              "10  capital    0.261089    0.280742\n",
              "11   berlin    0.254835    0.083837\n",
              "12  germany   -0.091155    0.123409\n",
              "13    paris    0.006388    0.267596\n",
              "14   france   -0.042966   -0.096859\n",
              "15    seoul    0.293198    0.175008\n",
              "16    korea   -0.081522   -0.023530\n",
              "17   bejing    0.097970    0.096438\n",
              "18    china    0.303941   -0.106828\n",
              "19    tokyo   -0.126865    0.176549\n",
              "20    japan    0.068725   -0.036306"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d536ffb9-cb3a-4a7e-90df-ca2b7d1e99cb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>임베딩벡터원소 x1</th>\n",
              "      <th>임베딩벡터원소 x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>he</td>\n",
              "      <td>0.043133</td>\n",
              "      <td>0.057207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>is</td>\n",
              "      <td>-0.041558</td>\n",
              "      <td>-0.134948</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>a</td>\n",
              "      <td>0.119008</td>\n",
              "      <td>0.122221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>king</td>\n",
              "      <td>0.101386</td>\n",
              "      <td>-0.073457</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>she</td>\n",
              "      <td>0.022029</td>\n",
              "      <td>0.019630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>queen</td>\n",
              "      <td>-0.079244</td>\n",
              "      <td>0.236107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>man</td>\n",
              "      <td>0.258880</td>\n",
              "      <td>-0.025212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>woman</td>\n",
              "      <td>-0.011290</td>\n",
              "      <td>-0.102319</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>warsaw</td>\n",
              "      <td>0.270881</td>\n",
              "      <td>0.117111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>poland</td>\n",
              "      <td>-0.064048</td>\n",
              "      <td>-0.091271</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>capital</td>\n",
              "      <td>0.261089</td>\n",
              "      <td>0.280742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>berlin</td>\n",
              "      <td>0.254835</td>\n",
              "      <td>0.083837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>germany</td>\n",
              "      <td>-0.091155</td>\n",
              "      <td>0.123409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>paris</td>\n",
              "      <td>0.006388</td>\n",
              "      <td>0.267596</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>france</td>\n",
              "      <td>-0.042966</td>\n",
              "      <td>-0.096859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>seoul</td>\n",
              "      <td>0.293198</td>\n",
              "      <td>0.175008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>korea</td>\n",
              "      <td>-0.081522</td>\n",
              "      <td>-0.023530</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>bejing</td>\n",
              "      <td>0.097970</td>\n",
              "      <td>0.096438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>china</td>\n",
              "      <td>0.303941</td>\n",
              "      <td>-0.106828</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>tokyo</td>\n",
              "      <td>-0.126865</td>\n",
              "      <td>0.176549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>japan</td>\n",
              "      <td>0.068725</td>\n",
              "      <td>-0.036306</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d536ffb9-cb3a-4a7e-90df-ca2b7d1e99cb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d536ffb9-cb3a-4a7e-90df-ca2b7d1e99cb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d536ffb9-cb3a-4a7e-90df-ca2b7d1e99cb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0b11819b-e7b7-421d-9fa7-ba4a0a31ac77\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0b11819b-e7b7-421d-9fa7-ba4a0a31ac77')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0b11819b-e7b7-421d-9fa7-ba4a0a31ac77 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_1a66c778-212e-4b2b-ac13-6411445fda53\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('w2v_df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_1a66c778-212e-4b2b-ac13-6411445fda53 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('w2v_df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "w2v_df",
              "summary": "{\n  \"name\": \"w2v_df\",\n  \"rows\": 21,\n  \"fields\": [\n    {\n      \"column\": \"word\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          \"he\",\n          \"bejing\",\n          \"seoul\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc784\\ubca0\\ub529\\ubca1\\ud130\\uc6d0\\uc18c x1\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.043133191764354706,\n          0.09796953946352005,\n          0.29319843649864197\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\uc784\\ubca0\\ub529\\ubca1\\ud130\\uc6d0\\uc18c x2\",\n      \"properties\": {\n        \"dtype\": \"float32\",\n        \"num_unique_values\": 21,\n        \"samples\": [\n          0.057206958532333374,\n          0.09643776714801788,\n          0.17500793933868408\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **벡터간 덧셈으로 Word가 벡터로 형성되었는지 파악**"
      ],
      "metadata": {
        "id": "u-F34_MEBnV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_x1 = w2v_df['임베딩벡터원소 x1'].values[6] - w2v_df['임베딩벡터원소 x1'].values[0] + w2v_df['임베딩벡터원소 x1'].values[4]\n",
        "test_x2 = w2v_df['임베딩벡터원소 x2'].values[6] - w2v_df['임베딩벡터원소 x2'].values[0] + w2v_df['임베딩벡터원소 x2'].values[4]\n",
        "print(test_x1, test_x2)\n",
        "print(w2v_df['임베딩벡터원소 x1'].values[7], w2v_df['임베딩벡터원소 x2'].values[7])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpRZFidr5eMl",
        "outputId": "fc4c600a-3fc0-46f9-c783-7d3ba1fb8912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.23777518 -0.06278897\n",
            "-0.011289637 -0.102319345\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **시각화 예제**\n",
        "ref: https://m.blog.naver.com/allieverwanted/222146678032"
      ],
      "metadata": {
        "id": "M_Qhbiih5GNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 보편적인 fig,ax = subplots()을 활용하는 방법\n",
        "fig, ax = plt.subplots(2,1)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "Swbd4WUm3uwT",
        "outputId": "c6b106e2-5f40-42b0-ee46-d9e7843af495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# axes가 담길수 있는 figure 객체를 만들기\n",
        "fig = plt.figure()\n",
        "\n",
        "# figure에 담길 axes 만들기 [행, 열, 몇번째 axes인가?]\n",
        "ax1 = fig.add_subplot(2, 1, 1)\n",
        "# ax2 = fig.add_subplot(2, 2, 2)\n",
        "ax2 = fig.add_subplot(2, 1, 2)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 435
        },
        "id": "7-N4UEXG4lXD",
        "outputId": "68c78437-a54d-41d3-a3ff-d551cce46bf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ano = w2v_df['word'].values\n",
        "print(ano)\n",
        "x1 = w2v_df['임베딩벡터원소 x1'].values\n",
        "print(x1)\n",
        "x2 = w2v_df['임베딩벡터원소 x2'].values\n",
        "print(x2)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5,5))\n",
        "ax.scatter(x1, x2)  # 두 변수의 상관 관계를 직교 좌표계의 평면에 점으로 표현하는 그래프\n",
        "\n",
        "for i, txt in enumerate(ano):\n",
        "    ax.annotate(txt, (x1[i],x2[i])) # 특정 위치에 주석(annotation)을 추가하는 데 사용"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "id": "VjRJ2RJpySHj",
        "outputId": "c04010a2-38e5-4cd9-fd22-b5045d4faed2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['he' 'is' 'a' 'king' 'she' 'queen' 'man' 'woman' 'warsaw' 'poland'\n",
            " 'capital' 'berlin' 'germany' 'paris' 'france' 'seoul' 'korea' 'bejing'\n",
            " 'china' 'tokyo' 'japan']\n",
            "[ 0.04313319 -0.04155827  0.11900751  0.10138563  0.02202886 -0.07924421\n",
            "  0.2588795  -0.01128964  0.27088133 -0.06404826  0.26108873  0.25483462\n",
            " -0.09115453  0.00638777 -0.0429658   0.29319844 -0.08152222  0.09796954\n",
            "  0.30394104 -0.12686506  0.06872483]\n",
            "[ 0.05720696 -0.13494752  0.12222149 -0.07345726  0.01962962  0.23610723\n",
            " -0.02521163 -0.10231934  0.11711135 -0.09127066  0.28074178  0.08383697\n",
            "  0.12340941  0.2675957  -0.09685888  0.17500794 -0.02352973  0.09643777\n",
            " -0.10682783  0.17654942 -0.03630592]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}