{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkcS7XEyWsjNdyFKryKWVB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagyeomkim/Deep-Learning-Paper-Review-and-Practice/blob/main/code_practice/Attention/Seq2Seq(Attention).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Luong의 General Version의 Attention 구현\n",
        "- code by: https://github.com/graykode/nlp-tutorial"
      ],
      "metadata": {
        "id": "3i35sPK-O1aJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VoWZaX5lF7fQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# S: Symbol that shows starting of decoding input\n",
        "# E: Symbol that shows starting of decoding output\n",
        "# P: Symbol that will fill in blank sequence if current batch data size is short than time steps\n",
        "\n",
        "def make_batch():\n",
        "    input_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[0].split()]]]\n",
        "    output_batch = [np.eye(n_class)[[word_dict[n] for n in sentences[1].split()]]]\n",
        "    target_batch = [[word_dict[n] for n in sentences[2].split()]]   # 배치 차원때문에, 대괄호 2개 써서 묶어줌\n",
        "\n",
        "    # make tensor\n",
        "    return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
        "\n",
        "# model\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Attention, self).__init__()\n",
        "        self.enc_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "        self.dec_cell = nn.RNN(input_size=n_class, hidden_size=n_hidden, dropout=0.5)\n",
        "\n",
        "        # Linear for attention\n",
        "        self.attn = nn.Linear(n_hidden, n_hidden)\n",
        "        self.out = nn.Linear(n_hidden * 2, n_class)\n",
        "\n",
        "    def forward(self, enc_inputs, hidden, dec_inputs):\n",
        "        enc_inputs = enc_inputs.transpose(0, 1) # enc_inputs: [max_len(=n_step; time_step), batch_size, n_class]\n",
        "        dec_inputs = dec_inputs.transpose(0, 1) # dec_inputs: [max_len(=n_step; time step), batch_size(=1), n_class]\n",
        "\n",
        "        # enc_outputs: [max_len(=n_step), batch_size, num_direction(=1) * n_hidden]\n",
        "        # enc_hidden: [num_layers(=1) * num_directions(=1), batch_size, n_hidden]\n",
        "        enc_outputs, enc_hidden = self.enc_cell(enc_inputs, hidden)\n",
        "\n",
        "        trained_attn = []\n",
        "        hidden =enc_hidden\n",
        "        n_step = len(dec_inputs)\n",
        "        model = torch.empty([n_step, 1, n_class])   # 1은 batch 크기\n",
        "\n",
        "        # -- Decoder --\n",
        "        for i in range(n_step): # each time step\n",
        "            # dec_inputs[i]: [batch_size, n_class]\n",
        "            # dec_output: [max_len(=n_step=1),batch_size(=1),num_directions(=1)*n_hidden]\n",
        "            # hidden: [num_layers(=1) * num_directions(=1), batch_size(=1), n_hidden]\n",
        "            dec_output, hidden = self.dec_cell(dec_inputs[i].unsqueeze(0), hidden)\n",
        "            attn_weights = self.get_att_weight(dec_output, enc_outputs) # attn_weights: [1, 1, n_step]\n",
        "            trained_attn.append(attn_weights.squeeze().detach().numpy())\n",
        "\n",
        "            # matrix-matrix product of matrices: [1,1,n_step] x [batch_size(학습데이터가 1개였으므로, 1), n_step, n_hidden] = [1, 1, n_hidden]\n",
        "            context = attn_weights.bmm(enc_outputs.transpose(0,1))\n",
        "\n",
        "            # --- concatenate ---\n",
        "            dec_output = dec_output.squeeze(0)  # [batch_size(=1), num_direcitons(=1) * n_hidden]\n",
        "            context = context.squeeze(1)    # [1, num_directions(=1) * n_hidden]\n",
        "            # torch.cat((dec_output, context), 1): [1, n_hidden * 2]\n",
        "            model[i] = self.out(torch.cat((dec_output, context), 1))    # model[i]: [1, n_class] <- n_step개 만큼 채워 넣음\n",
        "\n",
        "        # make model shape [n_step, n_class]\n",
        "        # model: [n_step, 1, n_class]\n",
        "        return model.transpose(0, 1).squeeze(0), trained_attn\n",
        "\n",
        "\n",
        "    def get_att_weight(self, dec_output, enc_outputs):  # get attention weight one 'dec_output' with 'enc_outputs'\n",
        "        \"\"\"\n",
        "        dec_output: [max_len(=n_step=1),batch_size(=1),num_directions(=1) * n_hidden]\n",
        "        enc_outputs: [max_len(=n_step), batch_size, num_direction(=1) * n_hidden]\n",
        "        \"\"\"\n",
        "        n_step = len(enc_outputs)\n",
        "        attn_scores = torch.zeros(n_step)   # attn_scores: [n_step]\n",
        "\n",
        "        for i in range(n_step): # encoder의 각 time step 별 output과의 score 구함\n",
        "            attn_scores[i] = self.get_att_score(dec_output, enc_outputs[i])\n",
        "\n",
        "        # Normalize scores to weights in range 0 to 1\n",
        "        return F.softmax(attn_scores).view(1, 1, -1)    # [1, 1, n_step]\n",
        "\n",
        "    def get_att_score(self, dec_output, enc_output):\n",
        "        \"\"\"\n",
        "        dec_output: [max_len(=n_step=1),batch_size(=1),num_directions(=1) * n_hidden] = [1, 1, n_hidden]\n",
        "        enc_output: [batch_size, num_directions(=1)*n_hidden] = [batch_size, n_hidden]\n",
        "        \"\"\"\n",
        "        # score: [batch_size, n_hidden]\n",
        "        score = self.attn(enc_output)\n",
        "        return torch.dot(dec_output.view(-1), score.view(-1))    # inner product make scalar value\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "    n_step = 5  # number of cells(=number of Step)\n",
        "    n_hidden = 128  # number of hidden units in one cell\n",
        "\n",
        "    sentences = ['ich mochte ein bier P', 'S i want a beer', 'i want a beer E']\n",
        "\n",
        "    word_list = \" \".join(sentences).split()\n",
        "    word_list = list(set(word_list))\n",
        "    word_dict = {w:i for i,w in enumerate(word_list)}   # word2index\n",
        "    number_dict = {i:w for i, w in enumerate(word_list)}    # index2word\n",
        "    n_class = len(word_dict)    # vocabulary\n",
        "\n",
        "    # hidden: [num_layers(=1)*num_directions(=1), batch_size, n_hidden]\n",
        "    hidden = torch.zeros(1, 1, n_hidden)\n",
        "    input_batch, output_batch, target_batch = make_batch()\n",
        "\n",
        "    model = Attention()\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "    # Train\n",
        "    for epoch in range(2000):\n",
        "        optimizer.zero_grad()\n",
        "        output, _ = model(input_batch, hidden, output_batch)\n",
        "\n",
        "        loss = criterion(output, target_batch.squeeze(0))\n",
        "        if (epoch + 1) % 400 == 0:\n",
        "            print(f'Epoch: {epoch+1:#04d} cost: {loss:.6f}')\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    # Test\n",
        "    test_batch = [np.eye(n_class)[[word_dict[n] for n in 'SPPPP']]]\n",
        "    test_batch = torch.FloatTensor(test_batch)\n",
        "    predict, trained_attn = model(input_batch, hidden, test_batch)\n",
        "    predict = torch.argmax(predict, dim=1)\n",
        "    print(sentences[0],'->', [number_dict[n.item()] for n in predict.squeeze()])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cjAlfhIGkV0",
        "outputId": "7acd798a-85c4-4d7a-925b-b3533e7d7eee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1566663511.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:254.)\n",
            "  return torch.FloatTensor(input_batch), torch.FloatTensor(output_batch), torch.LongTensor(target_batch)\n",
            "/usr/local/lib/python3.11/dist-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
            "  warnings.warn(\n",
            "/tmp/ipython-input-1566663511.py:72: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(attn_scores).view(1, 1, -1)    # [1, 1, n_step]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0400 cost: 0.000463\n",
            "Epoch: 0800 cost: 0.000149\n",
            "Epoch: 1200 cost: 0.000074\n",
            "Epoch: 1600 cost: 0.000043\n",
            "Epoch: 2000 cost: 0.000028\n",
            "ich mochte ein bier P -> ['i', 'want', 'a', 'beer', 'E']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `len()`: 0번째 차원의 크기 반환"
      ],
      "metadata": {
        "id": "2J6ar5TkKEr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Attention\n",
        "fig = plt.figure(figsize=(5, 5))\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.matshow(trained_attn, cmap='viridis')\n",
        "ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
        "ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "id": "dwZce5EAVdto",
        "outputId": "0968a750-c2be-487d-b2aa-f4787317c7d9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2673449293.py:5: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels([''] + sentences[0].split(), fontdict={'fontsize': 14})\n",
            "/tmp/ipython-input-2673449293.py:6: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_yticklabels([''] + sentences[2].split(), fontdict={'fontsize': 14})\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "-  특정 위치 (x, y)의 사각형 색이 밝을수록, 모델이 y축 단어를 생성할 때 x축 단어를 강하게 참고했다는 의미임"
      ],
      "metadata": {
        "id": "6djZrScWWzya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code Test"
      ],
      "metadata": {
        "id": "oSEVs6bzWtkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_batch = [[word_dict[n] for n in sentences[2].split()]]\n",
        "torch.LongTensor(target_batch).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kaJ53kzdIewS",
        "outputId": "7313503e-1088-48f3-b87d-d4a59f9c7777"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    }
  ]
}