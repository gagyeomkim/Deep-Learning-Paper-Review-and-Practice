{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gagyeomkim/Deep-Learning-Paper-Review-and-Practice/blob/main/code_practice/Sequence_to_Sequence_with_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Sequence to Sequence Learning with Neural Networks (NIPS 2014) 실습**\n",
        "\n",
        "- 본 코드는 **Attention을 이용하지 않은 Seq2Seq**으로 간단한 한글 챗봇을 제작합니다.\n",
        "    - 본 논문은 딥러닝 기반의 자연어 처리 기법의 기본적인 구성을 이해하고 공부하는 데에 도움을 줍니다.\n",
        "    - 2020년 기준 가장 뛰어난 번역 모델은 Seq2Seq가 아닌 Transformer 기반의 모델입니다.\n",
        "- 코드 실행 전에 **[런타임] → [런타임 유형 변경]** → 유형을 **GPU**로 설정합니다"
      ],
      "metadata": {
        "id": "vBIGnn7XC0hy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: https://teddylee777.github.io/pytorch/pytorch-seq2seq-chatbot/"
      ],
      "metadata": {
        "id": "AjPwqeZrE978"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **데이터 다운로드**"
      ],
      "metadata": {
        "id": "63zYdTPQE60d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd\n",
        "!mkdir data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnFTfyTIESNW",
        "outputId": "e6a7534b-cece-4929-e54e-11a7c5cb01b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- ref: https://me-coding.tistory.com/45"
      ],
      "metadata": {
        "id": "kXgJIV6sFJIR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv -O data/ChatbotData.csv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UNAkd8SD0qb",
        "outputId": "e6baba9f-cc5f-4ec2-d5d9-c523e780b98d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-07-10 21:01:21--  https://raw.githubusercontent.com/songys/Chatbot_data/refs/heads/master/ChatbotData.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 889842 (869K) [text/plain]\n",
            "Saving to: ‘data/ChatbotData.csv’\n",
            "\n",
            "data/ChatbotData.cs 100%[===================>] 868.99K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2025-07-10 21:01:22 (157 MB/s) - ‘data/ChatbotData.csv’ saved [889842/889842]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 형태소 분석기 다운로드"
      ],
      "metadata": {
        "id": "uoefLYJ-KXCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install konlpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "semFTvDoJOQS",
        "outputId": "117efecc-b86a-44d5-ce63-4ecc3d403566"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting JPype1>=0.7.0 (from konlpy)\n",
            "  Downloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m112.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jpype1-1.6.0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (496 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.6/496.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.6.0 konlpy-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zEUxezmnJ6R4",
        "outputId": "78b59996-93be-47fd-c6ed-239cec403890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (47/47), done.\u001b[K\n",
            "remote: Compressing objects: 100% (38/38), done.\u001b[K\n",
            "remote: Total 138 (delta 26), reused 22 (delta 8), pack-reused 91 (from 1)\u001b[K\n",
            "Receiving objects: 100% (138/138), 1.72 MiB | 32.52 MiB/s, done.\n",
            "Resolving deltas: 100% (65/65), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd Mecab-ko-for-Google-Colab"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4eWBiYDKnqd",
        "outputId": "c62eb0f9-ccd4-4be6-d4ec-668ba82d63f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Mecab-ko-for-Google-Colab\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash install_mecab-ko_on_colab_light_220429.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYMkKKXgKojU",
        "outputId": "86555235-fc62-40f1-8216-ffd3c803d635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing konlpy.....\n",
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (1.6.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2025-07-10 21:01:32--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 13.200.41.136, 13.200.41.134, 13.200.41.135, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|13.200.41.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNI5OYCMDB&Signature=gg5tz5gss878xk0Fj%2FJY3DfU4yk%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEL3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAVqPvSNaoYTfNOqh5Fa4ogibIy%2FEpQpPdD46aU9AQlEAiBNu%2BR0w4q38u3WhUtlv%2B1EYhrOUQuJ%2Fbt2Jab5I%2BslOCqwAgjG%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMeLVckni3KAVl8Ie0KoQCTtw%2FhjjnvGPQfakddjQHojEkS7s8i4WNFjA1O1TSXtTP4yGj0DXf4rn6WkSxbciKrCJ092A6sltYJiE0QEjV7oHOr67vT4Bpjvvihm%2Bz43vwNJc3JcEZpOCkxKsYC0uKUmWAOa5PUVOpDtJcwZrUAgyXI4cwORRgMBuz3uc3xEhD3KvG0HqjI8MnoWGz74BhXYTRYhx5B4CUsC4vliNiimNdkOAT%2BsSsQtQr96Bau0iIs8Mmy0%2Bizrc6xeZugtR02%2BQ7iZvR7kun5uLE%2BFSKKwXWvI0RnPz84ffu9Tpx%2F62xAYxz6Fku%2BC4XZI4FZaTVnKIxZb4wuBUAsXKM%2FvY8US5bnKgwnNTAwwY6ngFRiQcLEfAeLuLYT3B4YsMWPEm8v%2BpNCCkDG7Nhta57PRSuJixuAck4Nkm%2BIel5EudJP2k7INtrin%2Bjkw6NnEhPLMvRyeMomW9qUSQXbjWMwnIuezSiTf5sN1V5LVzoLnEwjcOSbJCGNKQkxTbaoB1q5Z5kIAzA68O9OxkckmKoQEYy2Uu75SU2gkd9HCl%2BI6QAgIv7pgF3Etbpl95fzg%3D%3D&Expires=1752183076 [following]\n",
            "--2025-07-10 21:01:33--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNI5OYCMDB&Signature=gg5tz5gss878xk0Fj%2FJY3DfU4yk%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEL3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIAVqPvSNaoYTfNOqh5Fa4ogibIy%2FEpQpPdD46aU9AQlEAiBNu%2BR0w4q38u3WhUtlv%2B1EYhrOUQuJ%2Fbt2Jab5I%2BslOCqwAgjG%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMeLVckni3KAVl8Ie0KoQCTtw%2FhjjnvGPQfakddjQHojEkS7s8i4WNFjA1O1TSXtTP4yGj0DXf4rn6WkSxbciKrCJ092A6sltYJiE0QEjV7oHOr67vT4Bpjvvihm%2Bz43vwNJc3JcEZpOCkxKsYC0uKUmWAOa5PUVOpDtJcwZrUAgyXI4cwORRgMBuz3uc3xEhD3KvG0HqjI8MnoWGz74BhXYTRYhx5B4CUsC4vliNiimNdkOAT%2BsSsQtQr96Bau0iIs8Mmy0%2Bizrc6xeZugtR02%2BQ7iZvR7kun5uLE%2BFSKKwXWvI0RnPz84ffu9Tpx%2F62xAYxz6Fku%2BC4XZI4FZaTVnKIxZb4wuBUAsXKM%2FvY8US5bnKgwnNTAwwY6ngFRiQcLEfAeLuLYT3B4YsMWPEm8v%2BpNCCkDG7Nhta57PRSuJixuAck4Nkm%2BIel5EudJP2k7INtrin%2Bjkw6NnEhPLMvRyeMomW9qUSQXbjWMwnIuezSiTf5sN1V5LVzoLnEwjcOSbJCGNKQkxTbaoB1q5Z5kIAzA68O9OxkckmKoQEYy2Uu75SU2gkd9HCl%2BI6QAgIv7pgF3Etbpl95fzg%3D%3D&Expires=1752183076\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 3.5.20.163, 3.5.29.86, 16.182.108.209, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|3.5.20.163|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M   888KB/s    in 1.6s    \n",
            "\n",
            "2025-07-10 21:01:36 (888 KB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2025-07-10 21:03:23--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 13.200.41.134, 13.200.41.135, 13.200.41.136, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|13.200.41.134|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCD7P4OM2&Signature=eGO%2FJwgKti2WvyJJzF0bC4dZ08I%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEL3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIH%2BIATUzSh9IrHmuE9uWUwaqXk2vkR6wg4SsEHqVnmIsAiAICN630xN2RnH0ldGqnkgBnPOq%2FD0dQeU5Wxxgif6ArCqwAgjG%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMnEezsXq385arVbLxKoQCnNCsfO54XkILy5mqQC4gKWAnyBW1BCuEClk7O3MEh%2BQ74JSh8LvuNNfGscpXIxq3hoUmzzOtFRCY4Hi3xRVxx2XUhkA42dOsOtNtSaLDUkGDIXJ4zdbhF8gd2xu0LGiG0xx7DVfDMZFoBzJICB%2FN4BIgAPujiHsxmUBghPBAIdBAkjWj4VyBBSnYlmOJ%2B14s%2FpvTNAm5eUht01iLMiBpA%2FL7jHp1w20JiSZJC0nGs5akcZFCFtGN7W0c%2Fb3GfLhsFm2Hz5Tmm6AERqSnXMmBBDWtqJsqCsHXRz4VBAsEokMP5D7BthYgmaySlmvW19CkWEULeRJEyz6OiGRf7oAOsI6kaeQwz87AwwY6ngHtNY2YSMfT1kNHpPQFLGhejNml3WHOIPqD7xHzH5RHZjctKi0uNlDntme4HloZqtFBMnaF2BFLQv5T8YOBLKq8iRrd8VBpN4OE7FtwH%2BZ2x8S%2BWBlCNbtKZ40Kzdz904hWyNrY1CMAVGWTWzb6xEm9%2F%2Fi7NUKanzzNL%2F9XilqDuVXpLR337UHInpWe8eEl9qOnfv8tRrD%2FBAnRqz3e1g%3D%3D&Expires=1752182359 [following]\n",
            "--2025-07-10 21:03:23--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None&AWSAccessKeyId=ASIA6KOSE3BNCD7P4OM2&Signature=eGO%2FJwgKti2WvyJJzF0bC4dZ08I%3D&x-amz-security-token=IQoJb3JpZ2luX2VjEL3%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEaCXVzLWVhc3QtMSJGMEQCIH%2BIATUzSh9IrHmuE9uWUwaqXk2vkR6wg4SsEHqVnmIsAiAICN630xN2RnH0ldGqnkgBnPOq%2FD0dQeU5Wxxgif6ArCqwAgjG%2F%2F%2F%2F%2F%2F%2F%2F%2F%2F8BEAAaDDk4NDUyNTEwMTE0NiIMnEezsXq385arVbLxKoQCnNCsfO54XkILy5mqQC4gKWAnyBW1BCuEClk7O3MEh%2BQ74JSh8LvuNNfGscpXIxq3hoUmzzOtFRCY4Hi3xRVxx2XUhkA42dOsOtNtSaLDUkGDIXJ4zdbhF8gd2xu0LGiG0xx7DVfDMZFoBzJICB%2FN4BIgAPujiHsxmUBghPBAIdBAkjWj4VyBBSnYlmOJ%2B14s%2FpvTNAm5eUht01iLMiBpA%2FL7jHp1w20JiSZJC0nGs5akcZFCFtGN7W0c%2Fb3GfLhsFm2Hz5Tmm6AERqSnXMmBBDWtqJsqCsHXRz4VBAsEokMP5D7BthYgmaySlmvW19CkWEULeRJEyz6OiGRf7oAOsI6kaeQwz87AwwY6ngHtNY2YSMfT1kNHpPQFLGhejNml3WHOIPqD7xHzH5RHZjctKi0uNlDntme4HloZqtFBMnaF2BFLQv5T8YOBLKq8iRrd8VBpN4OE7FtwH%2BZ2x8S%2BWBlCNbtKZ40Kzdz904hWyNrY1CMAVGWTWzb6xEm9%2F%2Fi7NUKanzzNL%2F9XilqDuVXpLR337UHInpWe8eEl9qOnfv8tRrD%2FBAnRqz3e1g%3D%3D&Expires=1752182359\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 16.182.97.153, 52.217.95.177, 52.216.111.43, ...\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|16.182.97.153|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  10.8MB/s    in 5.1s    \n",
            "\n",
            "2025-07-10 21:03:29 (9.37 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/v0.6.0/scripts/mecab.sh)\n",
            "https://github.com/konlpy/konlpy/issues/395#issue-1099168405 - 2022.01.11\n",
            "Done\n",
            "Install mecab-python\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n",
            "light 버전 작성 : Dogdriip님 ( https://github.com/Dogdriip )\n",
            "문제를 해결해주신 combacsa님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 원래 경로로 이동"
      ],
      "metadata": {
        "id": "5eltl6-LLrW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd ../"
      ],
      "metadata": {
        "id": "uDQiI7q3Li7U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bef67066-984a-4b1c-cc71-c9df32fc8ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모듈 import& 데이터로드**"
      ],
      "metadata": {
        "id": "AfkkQexjDOm3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqQlPmiGCsXW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "90607e97-dbd3-4558-f07b-d8ef04dedccf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "경로: data/ChatbotData.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Q                         A  label\n",
              "0                       12시 땡!                하루가 또 가네요.      0\n",
              "1                  1지망 학교 떨어졌어                 위로해 드립니다.      0\n",
              "2                 3박4일 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
              "3              3박4일 정도 놀러가고 싶다               여행은 언제나 좋죠.      0\n",
              "4                      PPL 심하네                눈살이 찌푸려지죠.      0\n",
              "...                        ...                       ...    ...\n",
              "11818           훔쳐보는 것도 눈치 보임.        티가 나니까 눈치가 보이는 거죠!      2\n",
              "11819           훔쳐보는 것도 눈치 보임.             훔쳐보는 거 티나나봐요.      2\n",
              "11820              흑기사 해주는 짝남.                    설렜겠어요.      2\n",
              "11821  힘든 연애 좋은 연애라는게 무슨 차이일까?  잘 헤어질 수 있는 사이 여부인 거 같아요.      2\n",
              "11822               힘들어서 결혼할까봐        도피성 결혼은 하지 않길 바라요.      2\n",
              "\n",
              "[11823 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2beeb00c-3d32-4ef2-bce5-3583c52eeedc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11818</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>티가 나니까 눈치가 보이는 거죠!</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11819</th>\n",
              "      <td>훔쳐보는 것도 눈치 보임.</td>\n",
              "      <td>훔쳐보는 거 티나나봐요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11820</th>\n",
              "      <td>흑기사 해주는 짝남.</td>\n",
              "      <td>설렜겠어요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11821</th>\n",
              "      <td>힘든 연애 좋은 연애라는게 무슨 차이일까?</td>\n",
              "      <td>잘 헤어질 수 있는 사이 여부인 거 같아요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11822</th>\n",
              "      <td>힘들어서 결혼할까봐</td>\n",
              "      <td>도피성 결혼은 하지 않길 바라요.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11823 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2beeb00c-3d32-4ef2-bce5-3583c52eeedc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2beeb00c-3d32-4ef2-bce5-3583c52eeedc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2beeb00c-3d32-4ef2-bce5-3583c52eeedc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ea50a045-5e12-4b18-8c97-6ba6f2571c6d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ea50a045-5e12-4b18-8c97-6ba6f2571c6d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ea50a045-5e12-4b18-8c97-6ba6f2571c6d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_a64d7cb5-faad-45b8-b0ee-a7cc10eed65b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_a64d7cb5-faad-45b8-b0ee-a7cc10eed65b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 11823,\n  \"fields\": [\n    {\n      \"column\": \"Q\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11662,\n        \"samples\": [\n          \"\\uc0ac\\ub791\\ud558\\ub294 \\uc0ac\\ub78c \\uc78a\\ub294 \\ubc95\",\n          \"\\uc220 \\uc548 \\uba39\\uc73c\\uba74 \\uce5c\\uad6c\\ub791 \\ubb50\\ud558\\uc9c0\",\n          \"\\uc9dd\\ub0a8\\uc774 \\uace0\\uc2dc\\uc0dd\\uc774\\uba74 \\uae30\\ub2e4\\ub824\\uc57c \\ud558\\ub098\\uc694?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"A\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 7779,\n        \"samples\": [\n          \"\\uc720\\uba38\\ucf54\\ub4dc\\uac00 \\ub9de\\ub294 \\uc0ac\\ub78c\\uc744 \\ucc3e\\uc544\\ubcf4\\uc138\\uc694.\",\n          \"\\uc5ec\\ud589\\uc744 \\ub5a0\\ub098 \\ubcf4\\uc138\\uc694.\",\n          \"\\ud589\\ubcf5\\ud560 \\uac70\\ub77c \\uc0dd\\uac01\\ud574\\uc694.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 2,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "data_dir = 'data'\n",
        "print(f\"경로: {os.path.join(data_dir, 'ChatbotData.csv')}\")\n",
        "df = pd.read_csv(os.path.join(data_dir, 'ChatbotData.csv'))\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['Q'])  # Series\n",
        "question = df['Q']\n",
        "\n",
        "print(df['A'])  # Series\n",
        "answer = df['A']"
      ],
      "metadata": {
        "id": "N3hQYw9aFZ03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43de2176-9b1d-4fc8-8892-470d9ce1775b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0                         12시 땡!\n",
            "1                    1지망 학교 떨어졌어\n",
            "2                   3박4일 놀러가고 싶다\n",
            "3                3박4일 정도 놀러가고 싶다\n",
            "4                        PPL 심하네\n",
            "                  ...           \n",
            "11818             훔쳐보는 것도 눈치 보임.\n",
            "11819             훔쳐보는 것도 눈치 보임.\n",
            "11820                흑기사 해주는 짝남.\n",
            "11821    힘든 연애 좋은 연애라는게 무슨 차이일까?\n",
            "11822                 힘들어서 결혼할까봐\n",
            "Name: Q, Length: 11823, dtype: object\n",
            "0                      하루가 또 가네요.\n",
            "1                       위로해 드립니다.\n",
            "2                     여행은 언제나 좋죠.\n",
            "3                     여행은 언제나 좋죠.\n",
            "4                      눈살이 찌푸려지죠.\n",
            "                   ...           \n",
            "11818          티가 나니까 눈치가 보이는 거죠!\n",
            "11819               훔쳐보는 거 티나나봐요.\n",
            "11820                      설렜겠어요.\n",
            "11821    잘 헤어질 수 있는 사이 여부인 거 같아요.\n",
            "11822          도피성 결혼은 하지 않길 바라요.\n",
            "Name: A, Length: 11823, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - Series란?: 인덱스와 일련의 값들로 구성된 인덱싱된 1차원 배열\n",
        "    - https://digital-play.tistory.com/31"
      ],
      "metadata": {
        "id": "c6_I2mykGTcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question[:5]    # 상위 5개 출력"
      ],
      "metadata": {
        "id": "QHiVQ33GFnTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ebb12315-aa50-4943-ddbc-106ff4e80d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0             12시 땡!\n",
              "1        1지망 학교 떨어졌어\n",
              "2       3박4일 놀러가고 싶다\n",
              "3    3박4일 정도 놀러가고 싶다\n",
              "4            PPL 심하네\n",
              "Name: Q, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[:5]  # 상위 5개 출력"
      ],
      "metadata": {
        "id": "io8JpzGBGhQo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ee2b10a0-fc15-4512-e93a-8cadff960864"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0     하루가 또 가네요.\n",
              "1      위로해 드립니다.\n",
              "2    여행은 언제나 좋죠.\n",
              "3    여행은 언제나 좋죠.\n",
              "4     눈살이 찌푸려지죠.\n",
              "Name: A, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>A</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>위로해 드립니다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **데이터 전처리**"
      ],
      "metadata": {
        "id": "WnzbHes3GlYx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **한글 정규화**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5XKMjzSuGoS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re   # 정규표현식 모듈\n",
        "\n",
        "# 한글, 영어, 숫자, 공백, ?!.,을 제외한 나머지 문자 제거\n",
        "korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'  # + : 1번이상 반복되는 문자\n",
        "\n",
        "# 패턴 컴파일\n",
        "normalizer = re.compile(korean_pattern)\n",
        "print(type(normalizer))\n",
        "normalizer"
      ],
      "metadata": {
        "id": "QOEP4uR0GkDs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "422eb5c3-62fe-4da5-afff-4fe39fbd1bec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 're.Pattern'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "re.compile(r'[^ ?,.!A-Za-z0-9가-힣+]', re.UNICODE)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> `re.compile`: 정규표현식을 컴파일하는 함수로, 패턴 객체가 만들어짐.   \n",
        "-> 매번 패턴을 컴파일하는 과정을 생략할 수 있어 속도와 편의성면에서 유리함\n",
        "- https://jh2021.tistory.com/7"
      ],
      "metadata": {
        "id": "sDf9tDs6HEP3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"수정 전 : {question[10]}\")\n",
        "print(f\"수정 후 : {normalizer.sub('',question[10])}\")   # 패턴객체.sub(바꿀 문자열, 원본 문자열)\n",
        "                                                      # 원본문자열에 있는 패턴을 \"바꿀 문자열\"로 변경"
      ],
      "metadata": {
        "id": "MD4VjyJnG__u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aaec3bc-7ce3-4dd1-d76e-a75c27ef83aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정 전 : SNS보면 나만 빼고 다 행복해보여\n",
            "수정 후 : SNS보면 나만 빼고 다 행복해보여\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"수정 전 : {answer[10]}\")\n",
        "print(f\"수정 후 : {normalizer.sub('',answer[10])}\")"
      ],
      "metadata": {
        "id": "r_xzdzHDIqPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4487503-ef69-4408-d269-f2194c76dceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "수정 전 : 자랑하는 자리니까요.\n",
            "수정 후 : 자랑하는 자리니까요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalize 함수로 일반화\n",
        "def normalize(sentence):\n",
        "    return normalizer.sub(\"\", sentence)\n",
        "\n",
        "normalize(question[10])"
      ],
      "metadata": {
        "id": "X1HsEP4SIyNn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "da606473-f703-4427-e1c7-0e4060ce04e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'SNS보면 나만 빼고 다 행복해보여'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **한글 형태소 분석기**"
      ],
      "metadata": {
        "id": "O4sUAxmtI_4q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Mecab 설치방법\n",
        "    - ref: https://github.com/SOMJANG/Mecab-ko-for-Google-Colab"
      ],
      "metadata": {
        "id": "-ely5LBwKBXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab, Okt   # 한국어 자연어 처리를 위한 패키지\n",
        "\n",
        "# 형태소 분석기\n",
        "mecab = Mecab()\n",
        "okt = Okt()"
      ],
      "metadata": {
        "id": "dnOudHl-I7yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Konlpy에서는 형태소 분석기에 모두 동일한 메소드를 지원함\n",
        "- `morphs()`: 형태소 추출\n",
        "- `pos()`: 품사 태깅\n",
        "- `nouns`: 명사 추출"
      ],
      "metadata": {
        "id": "O3da-DReLI6J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mecab\n",
        "mecab.morphs(normalize(question[10]))"
      ],
      "metadata": {
        "id": "ZDu2COxXJGHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59b95e11-0804-4928-ab5a-8e8242b1bf24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SNS', '보', '면', '나', '만', '빼', '고', '다', '행복', '해', '보여']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mecab\n",
        "mecab.morphs(normalize(answer[10]))"
      ],
      "metadata": {
        "id": "kdYnHxVwLyEP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6689bad-0bb7-42fd-ad90-9179b009f9a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['자랑', '하', '는', '자리', '니까요', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# okt\n",
        "okt.morphs(normalize(question[10]))"
      ],
      "metadata": {
        "id": "jgGzutjdLDAk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b60fd139-fa50-4211-a2d0-24dc6bcc1215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SNS', '보면', '나', '만', '빼고', '다', '행복', '해보여']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "okt.morphs(normalize(answer[10]))"
      ],
      "metadata": {
        "id": "BffhsVdfLz6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec168ba1-6215-4f5d-f982-428956b96cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['자랑', '하는', '자리', '니까', '요', '.']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ref: https://banmans.tistory.com/162  \n",
        "성능 순위 : mecab > komoran > kkma > hannanum > okt  \n",
        "속도 순위 : mecab >>> kkma > okt > hannanum > komoran"
      ],
      "metadata": {
        "id": "nnzDruj8L-C2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 한글 전처리를 함수화\n",
        "def clean_text(sentence, tagger):\n",
        "    sentence = normalize(sentence)  # 정규표현식 전처리\n",
        "    # print(sentence)\n",
        "    sentence = tagger.morphs(sentence)  # 형태소 추출\n",
        "    # print(sentence)\n",
        "    sentence = ' '.join(sentence)   # 추출한 형태소끼리 공백 1칸두고 합침\n",
        "    # print(sentence)\n",
        "    sentence = sentence.lower()  # 소문자 처리\n",
        "    # print(sentence)\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "sjXVvF33Lo04"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text(question[10], okt)"
      ],
      "metadata": {
        "id": "tLrv_-JQMWRg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9554e1d6-50d4-4dc7-c343-eb58d8180c8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sns 보면 나 만 빼고 다 행복 해보여'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clean_text(answer[10], okt)"
      ],
      "metadata": {
        "id": "L6LVMhpSMbw4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "0c4e4b7a-82af-4ccf-f009-d46690602afd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'자랑 하는 자리 니까 요 .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(question), len(answer)"
      ],
      "metadata": {
        "id": "N5qtwI-OMqqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abda8a48-0a4f-4dd3-a5b4-448bcbf9fbb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11823, 11823)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = [clean_text(sent, okt) for sent in question[:1000]]   # 1000개의 question을 clean_text해서 리스트로 보관\n",
        "\n",
        "answer = [clean_text(sent, okt) for sent in answer[:1000]]   # 1000개의 answer를 clean_text해서 리스트로 보관"
      ],
      "metadata": {
        "id": "mS1mIDszMwJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question[:5]"
      ],
      "metadata": {
        "id": "ahlD5XtTNEw4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81e16eb7-4eeb-420f-9b40-17213d547fff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['12시 땡 !', '1 지망 학교 떨어졌어', '3 박 4일 놀러 가고 싶다', '3 박 4일 정도 놀러 가고 싶다', 'ppl 심하네']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer[:5]"
      ],
      "metadata": {
        "id": "sJb9N1z5NUiU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ac7b575-41f8-4dbd-e8c9-198e9c643e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['하루 가 또 가네요 .',\n",
              " '위로 해 드립니다 .',\n",
              " '여행 은 언제나 좋죠 .',\n",
              " '여행 은 언제나 좋죠 .',\n",
              " '눈살 이 찌푸려지죠 .']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **단어 사전 생성**"
      ],
      "metadata": {
        "id": "rAW6XWYsNbY2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data.dataset import Dataset\n",
        "\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\") # GPU 0번 사용\n",
        "device"
      ],
      "metadata": {
        "id": "sVox4LC6NZgg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf18e33-5e19-458f-cc4e-d1726f8a76f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PAD_TOKEN = 0\n",
        "SOS_TOKEN = 1\n",
        "EOS_TOKEN = 2\n",
        "\n",
        "class WordVocab():\n",
        "    def __init__(self):\n",
        "        # word->idx\n",
        "        self.word2index = {\n",
        "            \"<PAD>\": PAD_TOKEN, # 시퀀스의 길이를 맞추기 위한 패딩 토큰. 시퀀스들의 길이를 동일하게 맞춰주기 위해 추가되는 토큰\n",
        "            \"<SOS>\": SOS_TOKEN, # 문장의 시작을 나타내는 토큰\n",
        "            \"<EOS>\": EOS_TOKEN, # 문장의 끝을 나타내는 토큰\n",
        "        }\n",
        "\n",
        "        # 각 토큰별 word_count\n",
        "        self.word2count = {}\n",
        "\n",
        "        # idx->word\n",
        "        self.index2word = {\n",
        "            PAD_TOKEN: \"<PAD>\",\n",
        "            SOS_TOKEN: \"<SOS>\",\n",
        "            EOS_TOKEN: \"<EOS>\",\n",
        "        }\n",
        "\n",
        "        # total word counts\n",
        "        self.n_words = 3    # <PAD>, <SOS>, <EOS> 포함 / # 새로운 단어는 index 3부터 시작\n",
        "\n",
        "    def add_sentence(self, sentence):\n",
        "        for word in sentence.split(' '):\n",
        "            self.add_word(word)\n",
        "\n",
        "    def add_word(self, word):\n",
        "        if word not in self.word2index:\n",
        "            self.word2index[word] = self.n_words    # n_words는 현재 단어 개수 = 새로 추가될 단어의 index\n",
        "            self.word2count[word] = 1   # 새로운 단어의 count=1\n",
        "            self.index2word[self.n_words] = word    # index2word에다가도 추가\n",
        "            self.n_words += 1   # 현재 단어개수 = 새로추가될 단어의 index를 +1시킴\n",
        "        else:\n",
        "            self.word2count[word] += 1"
      ],
      "metadata": {
        "id": "cX_9_LSYNvKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "question[10]"
      ],
      "metadata": {
        "id": "0AmteSmQOTd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "b3cccc7c-08f2-43ba-8c00-9d4729c740a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'sns 보면 나 만 빼고 다 행복 해보여'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"원문: {question[10]}\")\n",
        "lang = WordVocab()\n",
        "lang.add_sentence(question[10])\n",
        "print('=='*10)\n",
        "print('단어사전')\n",
        "print(lang.word2index)"
      ],
      "metadata": {
        "id": "PRg-AZXXPapx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3e3c7304-04ef-455f-8955-fb7427553f5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "원문: sns 보면 나 만 빼고 다 행복 해보여\n",
            "====================\n",
            "단어사전\n",
            "{'<PAD>': 0, '<SOS>': 1, '<EOS>': 2, 'sns': 3, '보면': 4, '나': 5, '만': 6, '빼고': 7, '다': 8, '행복': 9, '해보여': 10}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **padding to sequences**\n",
        "- 하나의 배치 구성을 위해서는 문장의 길이가 맞아야함\n",
        "- 문장별로 길이가 다르기 때문에 길이를 맞춰주는 작업 수행\n",
        "- 짧은 문장은 남는 공간에 `<PAD>` 토큰을 추가하여 길이를 맞춰줌"
      ],
      "metadata": {
        "id": "rqC7VaSCRL8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 10\n",
        "sentence_length = 6\n",
        "\n",
        "sentence_tokens = np.random.randint(low=3, high=100, size=(sentence_length,))\n",
        "# print(sentence_tokens)\n",
        "sentence_tokens = sentence_tokens.tolist()  # array를 파이썬 list로 바꿔줌\n",
        "print(f\"Generated Sentence: {sentence_tokens}\")\n",
        "\n",
        "sentence_tokens = sentence_tokens[:(max_length-1)]  # (max_length-1) 미만까지 자름 - <EOS> 토큰도 들어가야해서 max_length가 아님\n",
        "token_length = len(sentence_tokens)\n",
        "\n",
        "# 문장의 맨 끝부분에 <EOS>토큰 추가\n",
        "sentence_tokens.append(2)\n",
        "\n",
        "for i in range(token_length, max_length-1):\n",
        "    # 나머지 빈곳에 <PAD> 토큰 추가\n",
        "    sentence_tokens.append(0)   # 꼭 <EOS>토큰이 맨 마지막에 들어가는게 아님. <EOS>는 \"문장\" 끝에 들어가는거지 패딩된거끝에 들어가는게 아님\n",
        "\n",
        "print(f'Output: {sentence_tokens}')\n",
        "print(f'Total Length: {len(sentence_tokens)}')"
      ],
      "metadata": {
        "id": "-_tvGDuhPmSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e31be9a-49e7-453e-cd57-f9bf0feccd01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: [63, 16, 21, 76, 62, 13]\n",
            "Output: [63, 16, 21, 76, 62, 13, 2, 0, 0, 0]\n",
            "Total Length: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **전처리 프로세스 클래스화**(위의 내용을 모아둔 것)\n",
        "- torch.utils.data.Dataset을 상속받아 TextDataset 클래스를 구현\n",
        "- 데이터를 로드하고, 정규화 및 전처리, 토큰화를 진행함\n",
        "- 단어사전을 생성하고, 이에 따라 시퀀스로 변환"
      ],
      "metadata": {
        "id": "pNCXml-ITjAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from konlpy.tag import Mecab, Okt\n",
        "\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, csv_path, min_length, max_length=32):\n",
        "        super(TextDataset, self).__init__()\n",
        "        data_dir = 'data'\n",
        "\n",
        "        # TOKEN 정의\n",
        "        self.PAD_TOKEN = 0  # Padding Token\n",
        "        self.SOS_TOKEN = 1  # SOS 토큰\n",
        "        self.EOS_TOKEN = 2  # EOS 토큰\n",
        "\n",
        "        self.tagger = Mecab()   # 형태소 분석기\n",
        "        self.max_length = max_length    # 한 문장의 최대 길이 지정\n",
        "\n",
        "        # CSV 데이터 로드\n",
        "        df = pd.read_csv(os.path.join(data_dir, csv_path))\n",
        "\n",
        "        # 한글 정규화\n",
        "        korean_pattern = r'[^ ?,.!A-Za-z0-9가-힣+]'\n",
        "        self.normalizer = re.compile(korean_pattern)\n",
        "\n",
        "        # src: 질의, tgt: 답변\n",
        "        src_clean = []\n",
        "        tgt_clean = []\n",
        "\n",
        "        # 단어 사전 생성\n",
        "        wordvocab = WordVocab()\n",
        "\n",
        "        for _, row in df.iterrows():\n",
        "            src = row['Q']\n",
        "            tgt = row['A']\n",
        "\n",
        "            # 한글 전처리\n",
        "            src = self.clean_text(src)\n",
        "            tgt = self.clean_text(tgt)\n",
        "\n",
        "            if len(src.split()) > min_length and len(tgt.split()) > min_length:\n",
        "                # 최소 길이를 넘어가는 문장의 단어만 추가\n",
        "                wordvocab.add_sentence(src)\n",
        "                wordvocab.add_sentence(tgt)\n",
        "                src_clean.append(src)\n",
        "                tgt_clean.append(tgt)\n",
        "\n",
        "        self.srcs = src_clean\n",
        "        self.tgts = tgt_clean\n",
        "        self.wordvocab = wordvocab\n",
        "\n",
        "    def normalize(self, sentence):\n",
        "        return self.normalizer.sub('',sentence)\n",
        "\n",
        "    def clean_text(self, sentence):\n",
        "        # 한글 정규화\n",
        "        sentence = self.normalize(sentence)\n",
        "        # 형태소 처리\n",
        "        sentence = self.tagger.morphs(sentence)\n",
        "        sentence = ' '.join(sentence)\n",
        "        sentence = sentence.lower()\n",
        "        return sentence\n",
        "\n",
        "    def texts_to_sequences(self, sentence):\n",
        "        # 문장 -> 시퀀스로 변환\n",
        "        return [self.wordvocab.word2index[w] for w in sentence.split()]\n",
        "\n",
        "    def pad_sequence(self, sentence_tokens):\n",
        "        # 특별 토큰이 들어갈 공간 확보\n",
        "        sentence_tokens = sentence_tokens[:(self.max_length-1)]\n",
        "        token_length = len(sentence_tokens)\n",
        "        # print(sentence_tokens)\n",
        "        # 문장의 맨 끝 부분에 <EOS> 토큰 추가\n",
        "        sentence_tokens.append(self.EOS_TOKEN)\n",
        "\n",
        "        for i in range(token_length, (self.max_length-1)):\n",
        "            sentence_tokens.append(self.PAD_TOKEN)\n",
        "        return sentence_tokens\n",
        "\n",
        "    def __getitem__(self, idx): # 클래스의 인덱스에 접근할 때 자동으로 호출되는 메서드\n",
        "        inputs = self.srcs[idx] # clean_text된 문장\n",
        "        inputs_sequences = self.texts_to_sequences(inputs)\n",
        "        inputs_padded = self.pad_sequence(inputs_sequences)\n",
        "\n",
        "        outputs = self.tgts[idx]\n",
        "        outputs_sequences = self.texts_to_sequences(outputs)\n",
        "        outputs_padded = self.pad_sequence(outputs_sequences)\n",
        "\n",
        "        return torch.tensor(inputs_padded), torch.tensor(outputs_padded)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.srcs)"
      ],
      "metadata": {
        "id": "WGCK9j4BRw2h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 한 문장의 최대 단어 길이를 25로 설정\n",
        "MAX_LENGTH = 25\n",
        "dataset = TextDataset('ChatbotData.csv', min_length=3, max_length=MAX_LENGTH)"
      ],
      "metadata": {
        "id": "RZxQk2PoYdqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 10번째 데이터 임의 추출\n",
        "x, y = dataset[10]  # x: torch.tensor(inputs_padded), y: torch.tensor(outputs_padded)"
      ],
      "metadata": {
        "id": "_RIcdamSYp2J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'x shape: {x.shape}')\n",
        "print(x)"
      ],
      "metadata": {
        "id": "0ogID3PQYyDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86b24373-14e0-491e-c5e7-995aa9605407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x shape: torch.Size([25])\n",
            "tensor([83, 84, 51, 85, 86, 18,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'y shape: {y.shape}')\n",
        "print(y)"
      ],
      "metadata": {
        "id": "5E4If7MCaTYe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1474a160-0218-4a48-d01e-c607ef03b215"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y shape: torch.Size([25])\n",
            "tensor([87, 88, 58, 89, 63, 90, 11,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 문장의 맨 끝에는 2번 토큰(EOS 토큰)이 위치함\n",
        "- EOS 토큰부터 max_length까지는 PAD 토큰(0)으로 채워짐\n",
        "- x,y데이터 모두 max_length=25의 크기를 가짐"
      ],
      "metadata": {
        "id": "1r0R7TSHaXSX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **train/test 데이터 셋 분할**"
      ],
      "metadata": {
        "id": "Te8W-J5xa4HF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "id": "8ZMEthfzbGMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "433e3c06-f494-49ed-cd2d-fab66fc3b212"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10218"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 80%의 데이터를 train에 할당\n",
        "train_size = int(len(dataset) * 0.8)\n",
        "train_size"
      ],
      "metadata": {
        "id": "ZhtVwKmRaeFw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44a462d1-89be-4a31-ba83-6ef95c893840"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8174"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 나머지 20%의 데이터를 test에 할당\n",
        "test_size = len(dataset) - train_size\n",
        "test_size"
      ],
      "metadata": {
        "id": "kj-8c-wBa-QZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bc49431-1a73-42a6-bca5-86ca3eca860c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2044"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "# 랜덤 스플릿으로 분할을 완료합니다\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
      ],
      "metadata": {
        "id": "D16UBhWkbE0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **DataLoader 생성**\n",
        "- 배치구성을 쉽게 하기 위해 `torch.utils.data.DataLoader`를 활용\n",
        "- train/test 데이터셋 모두 batch_size=16으로 설정"
      ],
      "metadata": {
        "id": "fBdKPg5TbRUe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "train_loader = DataLoader(train_dataset,\n",
        "                          batch_size=16,    # 16개의 시퀀스를 한번에 처리\n",
        "                          shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,\n",
        "                         batch_size=16,\n",
        "                         shuffle=True)"
      ],
      "metadata": {
        "id": "9aG1dKXYbQnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- next와 iter 라는 함수를 사용하면 데이터셋 내부의 데이터를 하나하나씩 뽑을 수 있다.   \n",
        "(next는 파이썬의 iterator object에서 다음 아이템을 뽑는 함수고 iter는 어떤 오브젝트를 iterator로 바꿔주는 함수이다.)"
      ],
      "metadata": {
        "id": "BpkZcxxfcKL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1개의 배치 데이터를 추출\n",
        "x, y = next(iter(train_loader))"
      ],
      "metadata": {
        "id": "qat_KtnEbnYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# shape: (batch_size, sequence_length)\n",
        "x.shape, y.shape"
      ],
      "metadata": {
        "id": "lTs-R_vPbwWl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c329621-ec7b-43e1-e0cf-2c3856dd1fb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 25]), torch.Size([16, 25]))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **모델**"
      ],
      "metadata": {
        "id": "0xiiWUnQcZGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Encoder**"
      ],
      "metadata": {
        "id": "AZU8eHaxcc45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        # 단어 사전의 개수 지정\n",
        "        self.num_vocabs = num_vocabs\n",
        "        # 임베딩 레이어 정의(number of vocabs, embedding dimension)\n",
        "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
        "        # GRU(embedding dimension)\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                          hidden_size,\n",
        "                          num_layers=num_layers,\n",
        "                          bidirectional=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x).permute(1, 0, 2)\n",
        "        output, hidden = self.gru(x)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "d_0wyAPpbzzF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Embedding Layer의 입출력 shape에 대한 이해**\n",
        "- nn.Embedding: Input Tensor 를 다차원으로 확장시켜주는 기능"
      ],
      "metadata": {
        "id": "vy5K5UQndCnK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64  # 임베딩 차원\n",
        "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)  # 인자: (num_embeddigns, embedding_dim)\n",
        "embedded = embedding(x) # (sequence_length에 대해서 embedding_dim=64를 추가)\n",
        "\n",
        "print(x.shape)  # (batch_size, sequence_length)\n",
        "print(embedded.shape)   # (batch_size, sequence_length, embedding_dim)  <- 각 단어별로 embedding_dim 추가\n",
        "print(embedded)"
      ],
      "metadata": {
        "id": "gZSsfMuLdCDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "292b4984-dfc7-4be6-a24c-98c464439487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 25])\n",
            "torch.Size([16, 25, 64])\n",
            "tensor([[[ 0.1499, -0.6573,  1.5865,  ..., -0.7009,  0.3178, -0.1365],\n",
            "         [-0.2487, -1.3274, -0.4680,  ..., -0.8904,  0.7825, -1.2692],\n",
            "         [-0.4853,  0.0265,  0.5685,  ..., -0.4328,  0.6887,  1.8739],\n",
            "         ...,\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755]],\n",
            "\n",
            "        [[-0.1872, -0.4552,  0.1901,  ...,  0.7542, -1.0157,  0.5308],\n",
            "         [-1.5540, -0.7176,  1.1023,  ..., -0.8208, -0.3947,  0.9904],\n",
            "         [ 0.0239,  2.1469, -0.7227,  ..., -0.0692, -0.8305, -2.2648],\n",
            "         ...,\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755]],\n",
            "\n",
            "        [[ 0.7347, -1.1069,  0.0104,  ..., -0.0928,  0.0638,  0.3041],\n",
            "         [-1.0708, -0.0564, -0.8203,  ..., -2.3542,  1.2309,  0.8963],\n",
            "         [-1.8769,  1.4737,  0.9212,  ..., -1.2845,  0.3395, -0.3498],\n",
            "         ...,\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[ 0.1354, -0.6699, -0.4850,  ..., -0.2936,  0.6598,  0.1187],\n",
            "         [ 0.2926, -0.1304, -0.0686,  ...,  0.5435,  0.0093,  0.6404],\n",
            "         [ 1.6647, -0.7579, -1.3746,  ...,  0.3215, -0.2085, -0.6839],\n",
            "         ...,\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755]],\n",
            "\n",
            "        [[-0.3958,  0.3235,  1.6851,  ...,  0.3546, -0.3305,  1.6223],\n",
            "         [ 0.2218, -0.6652, -0.5650,  ..., -0.9699, -0.5204,  0.8167],\n",
            "         [ 1.3149,  1.1615, -0.7452,  ...,  0.0477, -0.0422, -1.2363],\n",
            "         ...,\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755]],\n",
            "\n",
            "        [[ 0.0825,  0.2137, -2.6179,  ...,  2.0642,  0.7116,  1.1347],\n",
            "         [-1.7332,  1.0285, -1.2875,  ...,  1.3356, -1.5203,  2.1483],\n",
            "         [-0.5380, -0.4716,  0.2409,  ...,  0.6592, -0.0329, -0.0891],\n",
            "         ...,\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755],\n",
            "         [-1.0751, -0.3323, -0.4610,  ...,  0.5498, -1.0972,  0.2755]]],\n",
            "       grad_fn=<EmbeddingBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedded = embedded.permute(1, 0, 2)    # (1번째 차원, 0번째 차원, 2번째 차원)이 되게 변경해라\n",
        "# (batch_size, sequence_length, , embedding_dim)\n",
        "# -> (sequence_length, batch_size, embedding_dim)\n",
        "\n",
        "print(embedded.shape)   # (sequence_length, batch_size, embedding_dim)"
      ],
      "metadata": {
        "id": "dChXjlo8dUFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87ad60c7-ed80-465c-ab0c-5a23f76e7271"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 16, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> - embedding layer를 통과한 출력을   \n",
        "`(batch_size, sequence_length, embedding_dim)`   \n",
        "=> `(sequence_length, batch_size, embedding_dim)` shape 변환을 위해 `permute(1,0,2)`를 수행함\n",
        "- shape을 변환하는 이유는 GRU 레이어의 입력이 `(sequence_length, batch_size, embedding_dim)`을 수용하기 때문"
      ],
      "metadata": {
        "id": "EBoWJOW_dtGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **GRU Layer의 입출력 shape에 대한이해**"
      ],
      "metadata": {
        "id": "90BHWOiNigF0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.pytorch.org/docs/stable/generated/torch.nn.GRU.html"
      ],
      "metadata": {
        "id": "lWVF2t6WkexK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `bidirectional`: true라면 양방향 GRU가 됨\n",
        "- `num_layers`: Number of recurrent layers\n",
        "- `o`: sequence의 모든 time step 별 hidden state를 모아놓은 텐서\n",
        "    -  아래 코드에 한해서는 **64차원의 단어 임베딩 벡터(입력)**를 받아,   \n",
        "    이전까지의 정보를 압축한 **문맥을 포함한 32차원의 은닉 상태 벡터(출력)**들로 만들어서 time step마다 모아둔 것\n",
        "- `h` : sequence의 가장 마지막 time step의 hidden state -> Context Vector\n",
        "    - 즉, `h`는 각 배치마다 마지막 hidden state를 모아놓은 텐서"
      ],
      "metadata": {
        "id": "sUolYvVZj-1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 32\n",
        "\n",
        "gru = nn.GRU(embedding_dim,  # embedding 차원\n",
        "             hidden_size,   # 문맥을 요약해서 만들 새로운 정보의 차원\n",
        "             num_layers=1,\n",
        "             bidirectional=False)\n",
        "\n",
        "# input(embedded): (sequence_length, batch_size, embedding_dim) = (25, 16, 64)\n",
        "# h0 : (bidirectional(1) * number of layers(1), batch_size, hidden_size) = (1, 16, 32)\n",
        "o, h = gru(embedded, None)  # 인자: (input, initial hidden state)\n",
        "\n",
        "# output(o): (sequence_length, batch_size, hidden_size * bidirectional(1))  = (25, 16, 32*1)\n",
        "# h: (bidirectional * num_layers, batch_size, hidden_size)  = (1, 16, 32)\n",
        "print(o.shape)\n",
        "print(h.shape)\n",
        "\n",
        "# output의 마지막 hidden state가 h랑 동일한것 확인 가능\n",
        "(o[-1] == h)"
      ],
      "metadata": {
        "id": "eNuNskC4iWk7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf03e5bd-bdd5-46ae-b763-d6bf909b8ee3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 16, 32])\n",
            "torch.Size([1, 16, 32])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True],\n",
              "         [True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True, True,\n",
              "          True, True, True, True, True, True, True, True, True, True]]])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Encoder의 입출력 shape에 대한 이해**"
      ],
      "metadata": {
        "id": "5NspLuC2nL8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_VOCABS = dataset.wordvocab.n_words\n",
        "print(f'number of vocabs: {NUM_VOCABS}')"
      ],
      "metadata": {
        "id": "A9hxPgVYjnVM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a52045fa-77bc-46b8-a3e4-1fcc4b26333f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of vocabs: 6435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder 정의\n",
        "encoder = Encoder(NUM_VOCABS, hidden_size=32, embedding_dim=64, num_layers=1)"
      ],
      "metadata": {
        "id": "nDynQXLVnSVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder에 x 통과후 output, hidden_size의 shape 확인\n",
        "# input(x): (batch_size, sequence_length)\n",
        "o, h = encoder(x)\n",
        "\n",
        "print(o.shape)  # (sequence_length, batch_size, hidden_size * bidirectional(1))\n",
        "print(h.shape)  # (bidirectional(1) * num_layers(1), batch_size, hidden_size)"
      ],
      "metadata": {
        "id": "_tezTajIna-F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee58b4b9-b95f-4421-c423-8ef92497e7db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 16, 32])\n",
            "torch.Size([1, 16, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Decoder**"
      ],
      "metadata": {
        "id": "g4sa3RTJo8oO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(nn.Module):\n",
        "    def __init__(self, num_vocabs, hidden_size, embedding_dim, num_layers=1, dropout=0.2):\n",
        "        super(Decoder, self).__init__() # 자식클래스(Decoder)가 상속받는 부모클래스(nn.Module)를 자식 클래스(Decoder)에 불러오겠다.\n",
        "        # 단어사전 개수\n",
        "        self.num_vocabs=num_vocabs\n",
        "        self.embedding = nn.Embedding(num_vocabs, embedding_dim)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.gru = nn.GRU(embedding_dim,\n",
        "                            hidden_size,\n",
        "                            num_layers=num_layers,\n",
        "                            bidirectional=False)\n",
        "        # 최종 출력은 단어사전의 개수\n",
        "        self.fc = nn.Linear(hidden_size, num_vocabs)\n",
        "\n",
        "    def forward(self, x, hidden_state):\n",
        "        x = x.unsqueeze(0)  # (1, batch_size)로 변환 <- 한번에 한 단어씩 순차적으로 다음 단어를 예측하기 때문에 seq_len = 1\n",
        "        embedded = F.relu(self.embedding(x))\n",
        "        embedded = self.dropout(embedded)\n",
        "        output, hidden = self.gru(embedded, hidden_state)\n",
        "        # print(output.shape)\n",
        "        # print(hidden.shape)\n",
        "        # print(output.squeeze(0).shape)\n",
        "        output = self.fc(output.squeeze(0)) # (sequence_length, batch_size, hidden_size(32) x bidirectional(1)\n",
        "        # print(output.shape)\n",
        "        return output, hidden"
      ],
      "metadata": {
        "id": "OH_eKyt1njFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `.squeeze(0)` : 0번째 차원이 1일 경우 제거\n",
        "    - hidden_state는 squeeze(0) 안해줌"
      ],
      "metadata": {
        "id": "iUrDetypwU9q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **Embedding Layer의 입출력 shape에 대한 이해**"
      ],
      "metadata": {
        "id": "BRtiSsZnsOFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.abs(torch.randn(size=(1,16)).long())\n",
        "print(x)\n",
        "print(x.shape)\n",
        "# batch_size = 16이라 가정했을 때,\n",
        "# x: (1, batch_size)\n",
        "# 여기서 batch_size => (1, batch_size)로 shape 변환을 선행"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcPSEjmJsNUs",
        "outputId": "e604ef72-efef-4a14-af97-c5ab2df2d4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0, 0, 1, 0, 0, 0, 2, 0, 0, 1, 1, 0, 1, 0]])\n",
            "torch.Size([1, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim = 64\n",
        "embedding = nn.Embedding(dataset.wordvocab.n_words, embedding_dim)\n",
        "\n",
        "embedded = embedding(x)\n",
        "print(x.shape)  # (1, 16)\n",
        "# embedding 출력\n",
        "print(embedded.shape)   # (1, batch_size, embedding_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gK95nkb5sUOX",
        "outputId": "7ad029e2-3da9-489c-8e0b-ebc052c059a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16])\n",
            "torch.Size([1, 16, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **GRU Layer의 입/출력 shape에 대한 이해**"
      ],
      "metadata": {
        "id": "WikXc6Y2tFGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_size = 32\n",
        "\n",
        "gru =nn.GRU(embedding_dim,\n",
        "            hidden_size,\n",
        "            num_layers=1,\n",
        "            bidirectional=False,\n",
        "            batch_first=False   # batch_first=False로 지정 => batch 차원이 0차원이 아님\n",
        "            )\n",
        "\n",
        "o, h = gru(embedded)\n",
        "print(o.shape)  # (sequence_length, batch_size, hidden_size * bidirectional(1)) = (1, 16, 32)\n",
        "print(h.shape)  # (bidirectional(1) * number of recurrent layers(1), batch_size, hidden_size) = (1, 16 , 32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoPJS5MQs2hC",
        "outputId": "149d7f80-ea71-4b13-a262-6c8e2f3546d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 32])\n",
            "torch.Size([1, 16, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **최종 출력층(FC) shape에 대한 이해**"
      ],
      "metadata": {
        "id": "ILK3Rn5Ut2Gn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fc = nn.Linear(32, NUM_VOCABS)  # 출력은 단어 사전의 개수로 가정\n",
        "output = fc(o[0])   # (, 32) -> (,NUM_VOCABS)\n",
        "\n",
        "print(o[0].shape)   # input: (batch_size, output from GRU)\n",
        "print(output.shape) # output: (batch_size, output_dim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaFR8GnXtrbB",
        "outputId": "3499cab0-c972-420d-e6c8-bef00eab350b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 32])\n",
            "torch.Size([16, 6435])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Encoder -> Decoder 입출력 shape**"
      ],
      "metadata": {
        "id": "JDV0OQsQuMuj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Decoder에 입력된 Encoder의 `output`, `hidden_state`의 shape을 확인\n"
      ],
      "metadata": {
        "id": "bx85wF74ujM7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(num_vocabs=dataset.wordvocab.n_words,\n",
        "                  hidden_size=32,\n",
        "                  embedding_dim=64,\n",
        "                  num_layers=1)"
      ],
      "metadata": {
        "id": "_Tk8u_79t_bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `hidden_state`만 디코더의 입력으로 활용함\n",
        "- `x`는 SOS 토큰이 첫번째 입력으로 들어감"
      ],
      "metadata": {
        "id": "lia0grGVuvpe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "o, h = encoder(x)\n",
        "print(o.shape, h.shape)\n",
        "# output: (sequence_length, batch_size, hidden_size(32)*bidirectional(1))\n",
        "# hidden_state: (bidirectional(1)*number of layers(1), batch_size, hidden_size(32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9B6L_yjwuvyc",
        "outputId": "100c8b0c-686f-4a2e-aded-bab3207e1eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([25, 16, 32]) torch.Size([1, 16, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- encoder로부터 생성된 hidden_state(`h`)와 SOS 토큰을 Decoder의 입력으로 넣어줌"
      ],
      "metadata": {
        "id": "QCcQosXrvXgP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.abs(torch.full(size=(16,), fill_value=SOS_TOKEN).long())\n",
        "print(x)\n",
        "x.shape\n",
        "# batch_size=16이라 가정(16개의 SOS 토큰)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNJBoEKKu_gr",
        "outputId": "66d23666-744f-42b3-cad3-b0dff123233e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder_output, decoder_hidden = decoder(x, h)\n",
        "decoder_output.shape, decoder_hidden.shape\n",
        "# (batch_size, num_vocabs), (1, batch_size, hidden_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMb45eYnvnHZ",
        "outputId": "1705af45-bc9e-4937-c165-4260b155bf75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 6435]), torch.Size([1, 16, 32]))"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `decoder_output`: (batch_size, num_vocabs) shape으로 출력\n",
        "- `decoder_hidden`: 입력으로 넣어준 shape과 동일"
      ],
      "metadata": {
        "id": "KN9x0UHTwyFq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Seq2Seq**"
      ],
      "metadata": {
        "id": "Fw48V0DhxMDp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 인코더: \"입력 문장이 무엇인지 처음부터 알고 있음.\" 따라서 전체 문장을 미리 받고 내부적으로 순차 처리하여 **하나의 요약본(Context Vector)**을 만드는 것이 목표. -> `input: (batch_size, seq_len=전체문장길이)`\n",
        "\n",
        "- 디코더: \"출력 문장이 무엇이 될지 전혀 모르는 상태에서 만들어가야함.\" 따라서 한 단어를 예측하고, 그 예측된 단어를 다음 입력으로 사용하는 과정을 반복해야함. 이 때문에 외부에서 **한 단어**씩 입력을 넣어주는 구조가 됨. `input: (batch_size, seq_len=1=한단어)`\n",
        "\n",
        "\n",
        "- 결론적으로, \"인코더도 내부적으로는 한 단어씩 처리하는 것이 맞다.\" 하지만 모델의 전체 구조상 '문장 전체를 한 번에 입력받아 요약하는 역할'을 하므로 입력 shape을 `(batch_size, seq_len)`로 표현"
      ],
      "metadata": {
        "id": "2kstby-12IrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Seq2Seq(nn.Module):\n",
        "    def __init__(self, encoder, decoder, device):\n",
        "        super(Seq2Seq, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.device = device\n",
        "\n",
        "    def forward(self, inputs, outputs, teacher_forcing_ratio=0.5):\n",
        "        # inputs: (batch_size, sequence_length)\n",
        "        # outputs: (batch_size, sequence_length)\n",
        "        batch_size, output_length = outputs.shape   # batch_size = batch_size, output_length = sequence_length\n",
        "        output_num_vocabs = self.decoder.num_vocabs\n",
        "\n",
        "        # 리턴할 예측된 outputs를 저장할 임시 변수\n",
        "        # predicted_outputs: (sequence_length, batch_size, num_vocabs) <- 문장의 모든 단어에 대한 예측을 저장할 수 있음\n",
        "        predicted_outputs = torch.zeros(output_length, batch_size, output_num_vocabs).to(self.device)\n",
        "\n",
        "        # 인코더에 입력 데이터 주입, encoder_output은 버리고 hidden state만 살림\n",
        "        # 여기서 hidden_state가 디코더에 주입할 context vector\n",
        "        # decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size)\n",
        "        _, decoder_hidden = self.encoder(inputs)\n",
        "\n",
        "        # (batch_size) shape의 SOS TOKEN으로 채워진 디코더 입력 생성\n",
        "        decoder_input = torch.full((batch_size, ), SOS_TOKEN, device=self.device)\n",
        "\n",
        "        # 순회하면서 출력 단어 생성\n",
        "        # 0번째는 SOS TOKEN이 위치하므로, 1번째 인덱스부터 순회\n",
        "        for t in range(0, output_length):\n",
        "            # decoder_input: 디코더 입력 (batch_size) 형태의 SOS TOKEN으로 채워진 입력\n",
        "            # decoder_output: (batch_size, num_vocabs) <- num_vocabs차원에는 다음으로 이 단어가 예측될것이다!라는 score값이 저장\n",
        "            # decoder_hidden: (Bidirectional(1) x number of layers(1), batch_size, hidden_size) = context vector와 동일 shape\n",
        "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
        "\n",
        "            # t번째 단어에 디코더의 output 저장\n",
        "            predicted_outputs[t] = decoder_output\n",
        "\n",
        "            # teacher forcing 적용 여부 확률로 결정\n",
        "            # teacher forcing이란: 정답지를 다음 RNN Cell의 입력으로 넣어주는 경우 수렴속도가 빠를 수 있으나, 불안정할 수 있음\n",
        "            teacher_force = random.random() < teacher_forcing_ratio\n",
        "\n",
        "            # top1 단어 토큰 예측\n",
        "            top1 = decoder_output.argmax(1) # num_vocabs차원상 가장 큰값\n",
        "\n",
        "            # teacher forcing인 경우 ground truth값을, 그렇지 않은 경우, 예측값을 다음 input으로 지정\n",
        "            decoder_input = outputs[:,t] if teacher_force else top1\n",
        "\n",
        "        return predicted_outputs.permute(1, 0, 2)   # (batch_size, sequence_length, num_vocabs)로 변경\n",
        "\n"
      ],
      "metadata": {
        "id": "7L6f6W6yw-Lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###### **seq2seq 입출력 확인**"
      ],
      "metadata": {
        "id": "GigUVxOJ4CuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# encoder 정의\n",
        "encoder = Encoder(num_vocabs=dataset.wordvocab.n_words,\n",
        "                  hidden_size=32,\n",
        "                  embedding_dim=64,\n",
        "                  num_layers=1)\n",
        "\n",
        "# decoder 정의\n",
        "decoder = Decoder(num_vocabs=dataset.wordvocab.n_words,\n",
        "                  hidden_size=32,\n",
        "                  embedding_dim=64,\n",
        "                  num_layers=1)\n",
        "\n",
        "# seq2seq 정의\n",
        "seq2seq = Seq2Seq(encoder, decoder, 'cpu')"
      ],
      "metadata": {
        "id": "Ljx5SOUG4AM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = next(iter(train_loader))\n",
        "print(x.shape, y.shape)\n",
        "# (batch_size, sequence_length), (batch_size, sequence_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2g8cJCVP4iJY",
        "outputId": "201f0a2b-f7d6-4e92-f6ff-8e59fe0761a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 25]) torch.Size([16, 25])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = seq2seq(x, y)\n",
        "print(output.shape) # (batch_size, sequence_length, num_vocabs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oehqzuc4lEF",
        "outputId": "e981d43a-aa71-418a-8b80-3389750eb847"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 25, 6435])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Training**"
      ],
      "metadata": {
        "id": "PegVKMYZ48HQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "NUM_VOCABS = dataset.wordvocab.n_words\n",
        "HIDDEN_SIZE = 512   # 원활한 결과를 위해 위의 예시에서 하이퍼파라미터 조정됨\n",
        "EMBEDDING_DIM = 256\n",
        "\n",
        "print(f\"num_vocabs: {NUM_VOCABS}\\n============================\")\n",
        "\n",
        "# Encoder 정의\n",
        "encoder = Encoder(num_vocabs=NUM_VOCABS,\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  embedding_dim=EMBEDDING_DIM,\n",
        "                  num_layers=1)\n",
        "\n",
        "# decoder 정의\n",
        "decoder = Decoder(num_vocabs=NUM_VOCABS,\n",
        "                  hidden_size=HIDDEN_SIZE,\n",
        "                  embedding_dim=EMBEDDING_DIM,\n",
        "                  num_layers=1)\n",
        "\n",
        "# Seq2Seq 생성\n",
        "# encoder, decoder를 device 모두 지정\n",
        "model = Seq2Seq(encoder.to(device), decoder.to(device), device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVomrRP44s58",
        "outputId": "d24d2642-3116-44d4-d13a-c5bc027b8be4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_vocabs: 6435\n",
            "============================\n",
            "Seq2Seq(\n",
            "  (encoder): Encoder(\n",
            "    (embedding): Embedding(6435, 256)\n",
            "    (gru): GRU(256, 512)\n",
            "  )\n",
            "  (decoder): Decoder(\n",
            "    (embedding): Embedding(6435, 256)\n",
            "    (dropout): Dropout(p=0.2, inplace=False)\n",
            "    (gru): GRU(256, 512)\n",
            "    (fc): Linear(in_features=512, out_features=6435, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **HyperParameter 정의**"
      ],
      "metadata": {
        "id": "bP3MRHqA50cW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarlyStopping:\n",
        "    def __init__(self, patience=3, delta=0.0, mode='min', verbose=True):\n",
        "        \"\"\"\n",
        "        patience (int): loss or score가 개선된 후 기다리는 기간. default: 3 / 성능이 나아지지 않더라도 3번의 epoch까지는 더 기다려봄\n",
        "        delta  (float): 개선시 인정되는 최소 변화 수치. default: 0.0    /   미미한 성능향상을 무시하고 싶을 때 설정 가능\n",
        "        mode     (str): 개선시 최소/최대값 기준 선정('min' or 'max'). default: 'min'.   / loss: 값이 낮을 수록 좋음 -> min 사용 , accuracy: 값이 높을 수록 좋음 ->  max 사용\n",
        "        verbose (bool): 메시지 출력여부 결정. default: True\n",
        "        \"\"\"\n",
        "        self.early_stop = False\n",
        "        self.patience = patience\n",
        "        self.verbose = verbose\n",
        "        self.counter = 0\n",
        "\n",
        "        self.best_score = np.inf if mode == 'min' else 0\n",
        "        self.mode = mode\n",
        "        self.delta = delta\n",
        "\n",
        "    # __call__: 클래스의 인스턴스를 함수처럼 호출 가능하게 만들어줌\n",
        "    def __call__(self, score):\n",
        "        if self.best_score is None: # best_score가 없다면\n",
        "            self.best_score = score\n",
        "            self.counter = 0\n",
        "        elif self.mode == 'min':    # best_score가 존재하고, mode==min\n",
        "            if score < (self.best_score - self.delta):  # 성능향상이 이루어졌다면\n",
        "                self.counter = 0\n",
        "                self.best_score = score\n",
        "                if self.verbose:\n",
        "                    print(f'[EarlyStopping] (Update) Best Score: {self.best_score:.5f}')\n",
        "            else:   # 성능향상이 이루어지지 않았다면\n",
        "                self.counter += 1\n",
        "                if self.verbose:\n",
        "                    print(f'[EarlyStopping] (Patience) {self.counter}/{self.patience}, ' \\\n",
        "                          f'Best: {self.best_score:.5f}' \\\n",
        "                          f', Current: {score:.5f}, Delta: {np.abs(self.best_score - score):.5f}')\n",
        "\n",
        "        elif self.mode == 'max':    # best_score가 존재하고, mode!=min, mode=max\n",
        "            if score > (self.best_score + self.delta):  # 성능향상이 이루어졌다면\n",
        "                self.counter = 0\n",
        "                self.best_score = score\n",
        "                if self.verbose:\n",
        "                    print(f'[EarlyStopping] (Update) Best Score: {self.best_score:.5f}')\n",
        "            else:   # 성능향상이 이루어지지 않았다면\n",
        "                self.counter += 1\n",
        "                if self.verbose:\n",
        "                    print(f'[EarlyStopping] (Patience) {self.counter}/{self.patience}, ' \\\n",
        "                          f'Best: {self.best_score:.5f}' \\\n",
        "                          f', Current: {score:.5f}, Delta: {np.abs(self.best_score - score):.5f}')\n",
        "\n",
        "\n",
        "        if self.counter >= self.patience:   # patience만큼의 epoch을 기다렸는데도 성능향상이 이루어지지 않았다면\n",
        "            if self.verbose:\n",
        "                print(f'[EarlyStop Triggered] Best Score: {self.best_score:.5f}')   # 최종 스코어 출력\n",
        "            # Early Stop\n",
        "            self.early_stop = True\n",
        "        else:\n",
        "            # Continue\n",
        "            self.early_stop = False"
      ],
      "metadata": {
        "id": "Zv2e40D85iPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 훈련에 적용할 하이퍼파라미터 설정"
      ],
      "metadata": {
        "id": "KuoDt8tO7bOM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LR = 1e-3\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "loss_fn = nn.CrossEntropyLoss() # softmax함수가 포함되어져있음\n",
        "\n",
        "es = EarlyStopping(patience=5,\n",
        "                   delta=0.001,\n",
        "                   mode='min',\n",
        "                   verbose=True\n",
        "                  )\n",
        "# ReduceLROnPlateau: 검증 손실(validation loss)이 더 이상 개선되지 않을 때 학습률을 동적으로 감소시켜 모델의 학습을 돕는 기법\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, # 옵티마이저객체\n",
        "                                                 mode='min',    # 성능 개선 측정 방법\n",
        "                                                 factor=0.5,    # learning_rate를 감소시킬 비율; 현재 lr에 * 0.5\n",
        "                                                 patience=2,    # 더이상 성능 개선 안되어도 2번의 연속적인 epoch동안 기다림\n",
        "                                                 threshold_mode='abs',  # 절대적인 변화량으로 threshold를 해석함\n",
        "                                                                        # threshold: learning rate를 감소시킬 기준\n",
        "                                                 min_lr=1e-8,   # learning rate를 감소시킬 최솟값. learning_rate는 이 값보다 작아지지 않음\n",
        "                                                 verbose=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_FXrkqC7att",
        "outputId": "2067728a-fc8d-4cd1-fc4c-882a9d32087c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **trian 함수 정의**"
      ],
      "metadata": {
        "id": "Z1ix4js_8E9g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, data_loader, optimizer, loss_fn, device):\n",
        "    model.train()   # 학습모드로 설정\n",
        "    running_loss=0\n",
        "\n",
        "    for x, y in data_loader:\n",
        "        x, y = x.to(device), y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # output: (batch_size, sequence_length, num_vocabs)\n",
        "        output = model(x, y)\n",
        "        output_dim = output.size(2) # output_dim: num_vocabs\n",
        "\n",
        "        # 1번 index부터 슬라이싱한 이유는 0번 index가 SOS TOKEN이기 때문\n",
        "        # (batch_size * sequnce_length, num_vocabs)로 변경\n",
        "        output = output.reshape(-1, output_dim) # 배치 내 모든 문장에 있는 **단어 위치별** 예측 결과\n",
        "\n",
        "        # y:(batch_size, sequence_length) -> (batch_size * sequence_length)로 변경\n",
        "        y = y.view(-1)  # 간단하게, 밖을 둘러싸고 있던 `[]`하나가 사라짐\n",
        "\n",
        "        # loss 계산\n",
        "        # CrossEntropyLos의 input은 (N,C)이라는 2차원을 수용함\n",
        "        # N: 배치 내에 포함된 모든 개별 토큰(단어)의 총 개수, C: number of classes\n",
        "        loss = loss_fn(output,y)    # (1,) shape을 갖는 텐서 -> loss.item()으로 가지고 와야함\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item() * x.size(0)# loss는 보통 한 배치에 대한 평균을 계산 -> 배치 내 모든 문장에 대한 총 손실로 변경\n",
        "\n",
        "    return running_loss / len(data_loader)  # 배치 개수로 loss를 평균내서 리턴"
      ],
      "metadata": {
        "id": "81if0I4y73bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "t = np.random.randn(2, 4, 3)\n",
        "print(t.shape)\n",
        "print(t)\n",
        "print('-'*50)\n",
        "print(t.reshape(-1, 3).shape)\n",
        "print(t.reshape(-1, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnFyh-m4_HTo",
        "outputId": "3999bad7-17be-497f-c28e-9be0da0e99a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2, 4, 3)\n",
            "[[[ 0.72370057 -1.59634392 -0.19806267]\n",
            "  [-0.71904181  0.29846875 -0.93228796]\n",
            "  [ 2.27514803 -1.54657777  0.8648444 ]\n",
            "  [ 0.11272371  0.20671143  1.72048111]]\n",
            "\n",
            " [[-1.01671768  0.40326562 -0.74633451]\n",
            "  [-0.5216068   1.16752092 -0.47201208]\n",
            "  [ 1.3336449   1.64377082  1.59777122]\n",
            "  [-0.19518903  0.59222514  0.05467594]]]\n",
            "--------------------------------------------------\n",
            "(8, 3)\n",
            "[[ 0.72370057 -1.59634392 -0.19806267]\n",
            " [-0.71904181  0.29846875 -0.93228796]\n",
            " [ 2.27514803 -1.54657777  0.8648444 ]\n",
            " [ 0.11272371  0.20671143  1.72048111]\n",
            " [-1.01671768  0.40326562 -0.74633451]\n",
            " [-0.5216068   1.16752092 -0.47201208]\n",
            " [ 1.3336449   1.64377082  1.59777122]\n",
            " [-0.19518903  0.59222514  0.05467594]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **evaluation 함수 정의**"
      ],
      "metadata": {
        "id": "1yzL2ZKy86c3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, data_loader, loss_fn, device):\n",
        "    model.eval()    # 모델 평가시 사용. Dropout, Batchnorm등의 기능들을 비활성화해준다고 한다.\n",
        "                    # 모델링 시 training과 inference시에 다르게 동작하는 layer들이 존재하기 때문에 사용\n",
        "\n",
        "    eval_loss = 0\n",
        "\n",
        "    with torch.no_grad():   # autograd를 끔으로써 메모리 사용량을 줄이고 연산 속도를 높히기 위함\n",
        "        for x, y in data_loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x, y)\n",
        "            output_dim = output.size(2)\n",
        "            output = output.reshape(-1, output_dim)\n",
        "            y = y.view(-1)\n",
        "\n",
        "            # Loss 계산\n",
        "            loss = loss_fn(output, y)\n",
        "\n",
        "            eval_loss += loss.item() * x.size(0)\n",
        "\n",
        "    return eval_loss / len(data_loader)"
      ],
      "metadata": {
        "id": "lByaUqz98599"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **랜덤 샘플링 후 결과 추론**"
      ],
      "metadata": {
        "id": "JESq0EXk9SU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- sequence를 다시 문장으로 바꾸어 문장 형식으로 출력하기 위한 함수"
      ],
      "metadata": {
        "id": "2BPXTXUo9oDa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sequence_to_sentence(sequences, index2word):\n",
        "    outputs = []\n",
        "    for p in sequences: # 시퀀스에 있는 정수 인덱스를 한개씩 가져옴\n",
        "\n",
        "        word = index2word[p]\n",
        "        if p not in [SOS_TOKEN, EOS_TOKEN, PAD_TOKEN]:  #  토큰에 안들어가면\n",
        "            outputs.append(word)\n",
        "        if word == EOS_TOKEN:   # EOS TOKEN을 만나면\n",
        "            break\n",
        "    return ' '.join(outputs)"
      ],
      "metadata": {
        "id": "E-VTRtT19R-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_evaluation(model, dataset, index2word, device, n=10):\n",
        "\n",
        "    n_samples = len(dataset)    # data sample의 개수\n",
        "    indices = list(range(n_samples))    # [0~n_samples-1]를 포함한 인덱스 생성\n",
        "    np.random.shuffle(indices)      # Shuffle\n",
        "    sampled_indices = indices[:n]   # Sampling N indices\n",
        "\n",
        "    # 샘플링한 데이터를 기반으로 DataLoader 생성\n",
        "    sampler = SubsetRandomSampler(sampled_indices)  # SubsetRandomSampler: 주어진 인덱스목록에서 요소를 무작위로샘플링함\n",
        "    sampled_dataloader = DataLoader(dataset, batch_size=10, sampler=sampler)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in sampled_dataloader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x, y, teacher_forcing_ratio=0)   # 평가시에는 teacher forcing 안씀\n",
        "            # output: (number of samples, sequence_length, num_vocabs)\n",
        "\n",
        "            # PyTorch 텐서를 NumPy 배열로 변환하여 학습 외의 다른 목적으로 사용할 수 있도록 하기 위해서 사용(아래의 반복문)\n",
        "            preds = output.detach().cpu().numpy()   # GPU에 올라가 있는 tensor를 이용하려면 numpy 또는 list로 변환해야함\n",
        "            x = x.detach().cpu().numpy()    # GPU에 올라가 있는 tensor를 이용하려면 numpy 또는 list로 변환\n",
        "            y = y.detach().cpu().numpy()    # GPU에 올라가 있는 tensor를 이용하려면 numpy 또는 list로 변환\n",
        "\n",
        "            for i in range(n):\n",
        "                print(f'질문   : {sequence_to_sentence(x[i], index2word)}')\n",
        "                print(f'답변   : {sequence_to_sentence(y[i], index2word)}')\n",
        "                print(f'예측답변: {sequence_to_sentence(preds[i].argmax(1), index2word)}')\n",
        "                print('==='*10)"
      ],
      "metadata": {
        "id": "q1zN-nUT9nGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- detach(): 연산 기록에서 역전파를 중단하고 분리한 텐서 반환\n",
        "- cpu(): GPU 메모리에 올라가있는 tensor를 CPU메모리로 복사\n",
        "- numpy(): CPU 메모리에 올려져 있는 tensor만 해당 함수를 적용가능. tensor를 numpy로 변환해줌"
      ],
      "metadata": {
        "id": "zTq4ZSkYG25s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "idx = list(range(10))\n",
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60X_yojvFGvQ",
        "outputId": "44e9f2da-e4c1-4c55-a6ba-00e27f339651"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(idx)\n",
        "idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaO15Z5TFdAd",
        "outputId": "c5e77af3-ca4b-4a45-8616-799a4f097c92"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[9, 0, 4, 6, 3, 5, 7, 1, 2, 8]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **훈련 시작**"
      ],
      "metadata": {
        "id": "ao0xXXhX-nzr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "bEiVYUns_0KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모델저장하기: https://tutorials.pytorch.kr/beginner/saving_loading_models.html"
      ],
      "metadata": {
        "id": "5R9AW2GODcMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_EPOCHS = 20\n",
        "STATEDICT_PATH = 'models/seq2seq-chatbot-kor.pt'\n",
        "\n",
        "best_loss = np.inf\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    loss = train(model, train_loader, optimizer, loss_fn, device)\n",
        "\n",
        "    val_loss = evaluate(model, test_loader, loss_fn, device)\n",
        "\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        torch.save(model.state_dict(), STATEDICT_PATH)\n",
        "\n",
        "    if epoch % 5 == 0:  # 5번째 epoch마다\n",
        "        print(f'epoch: {epoch+1}, loss: {loss:.4f}, val_loss: {val_loss:.4f}')\n",
        "\n",
        "    # Early Stop\n",
        "    es(loss)\n",
        "    if es.early_stop:\n",
        "        break\n",
        "\n",
        "    # Scheduler\n",
        "    scheduler.step(val_loss)\n",
        "\n",
        "# .load_state_dict(): torch.load()로 불러온 딕셔너리를 실제 모델 객체에 적용하는 역할\n",
        "model.load_state_dict(torch.load(STATEDICT_PATH))   # load_state_dict() 함수에는 저장된 객체의 경로가 아닌, 사전 객체를 전달\n",
        "                                                    # torch.load(PATH): 파이썬 딕셔너리 객체로 되돌려둠\n",
        "                                                    # 모델.load_state_dict(): 모델에 불러온 딕셔너리 적용\n",
        "torch.save(model.state_dict(), f'models/seq2seq-chatbot-kor-{best_loss:.4f}.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BamJDkFs-mv9",
        "outputId": "2c46cd00-9860-405c-e2c6-896cfb3f97d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1, loss: 32.6597, val_loss: 29.2692\n",
            "[EarlyStopping] (Update) Best Score: 32.65969\n",
            "[EarlyStopping] (Update) Best Score: 28.12655\n",
            "[EarlyStopping] (Update) Best Score: 26.08314\n",
            "[EarlyStopping] (Update) Best Score: 23.97805\n",
            "[EarlyStopping] (Update) Best Score: 21.29754\n",
            "epoch: 6, loss: 18.4086, val_loss: 26.8496\n",
            "[EarlyStopping] (Update) Best Score: 18.40861\n",
            "[EarlyStopping] (Update) Best Score: 15.51410\n",
            "[EarlyStopping] (Update) Best Score: 12.86352\n",
            "[EarlyStopping] (Update) Best Score: 9.37432\n",
            "[EarlyStopping] (Update) Best Score: 7.46079\n",
            "epoch: 11, loss: 6.2363, val_loss: 29.9187\n",
            "[EarlyStopping] (Update) Best Score: 6.23629\n",
            "[EarlyStopping] (Update) Best Score: 4.75839\n",
            "[EarlyStopping] (Update) Best Score: 4.07226\n",
            "[EarlyStopping] (Update) Best Score: 3.53820\n",
            "[EarlyStopping] (Update) Best Score: 2.85709\n",
            "epoch: 16, loss: 2.5622, val_loss: 33.0285\n",
            "[EarlyStopping] (Update) Best Score: 2.56222\n",
            "[EarlyStopping] (Update) Best Score: 2.37652\n",
            "[EarlyStopping] (Update) Best Score: 2.09646\n",
            "[EarlyStopping] (Update) Best Score: 2.02564\n",
            "[EarlyStopping] (Update) Best Score: 1.88043\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 결과"
      ],
      "metadata": {
        "id": "sLqh_5rA_THA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(STATEDICT_PATH))\n",
        "random_evaluation(model, test_dataset, dataset.wordvocab.index2word, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV2Wv2ch_R_o",
        "outputId": "cee02210-e6fa-4255-c775-8bbd1bd6d621"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "질문   : 추억 에 머물 다 .\n",
            "답변   : 때로 는 추억 이 힘 이 되 기 도 하 죠 .\n",
            "예측답변: 생각 이 웬수 나 봐요 .\n",
            "==============================\n",
            "질문   : 좋 아 하 는 애 가 좀 노 는 애 인데 좋 아 해도 돼 ?\n",
            "답변   : 어떤 사람 이 냐 에 따라 다릅니다 .\n",
            "예측답변: 좋 하 는 게 좋 을 것 같 아요 .\n",
            "==============================\n",
            "질문   : 베란다 도 꾸미 니까 예쁘 더라 .\n",
            "답변   : 심플 하 게 꾸며 보 세요 .\n",
            "예측답변: 이제 한 순간 이 있 .\n",
            "==============================\n",
            "질문   : 대리 님 이 너무 갈궈\n",
            "답변   : 더 웃 으면서 대해 보 세요 .\n",
            "예측답변: 더 한 아이스크림 좋 을 거 예요 .\n",
            "==============================\n",
            "질문   : 오늘 화장 이 안 먹 어\n",
            "답변   : 각질 제거 를 해 보 세요 .\n",
            "예측답변: 건강 한 과일 먹 고 맛있 세요 .\n",
            "==============================\n",
            "질문   : 생리통 때문 에 배 아파\n",
            "답변   : 힘들 겠 어요 .\n",
            "예측답변: 잘 하 지 마세요 .\n",
            "==============================\n",
            "질문   : 오늘 은 결재 가 나야 할텐데\n",
            "답변   : 그럴 수 있 을 거 예요 .\n",
            "예측답변: 잘 할 수 있 을 거 예요 .\n",
            "==============================\n",
            "질문   : 과함 설렘 후 에 지금 은 안 설레\n",
            "답변   : 초반 에 너무 설렜 나 봐요 .\n",
            "예측답변: 은연 중 에 는 생각 이 에요 .\n",
            "==============================\n",
            "질문   : 약 챙겨 먹 어야지\n",
            "답변   : 꼬박꼬박 챙겨 드세요 .\n",
            "예측답변: 건강 한 과일 드세요 .\n",
            "==============================\n",
            "질문   : 이 사람 은 사랑 이 참 쉬운가 봐 내 가 우습 나 ?\n",
            "답변   : 참 을 수 없 는 가벼움 이 네요 .\n",
            "예측답변: 사랑 은 는 이 없 는 것 도 중요 해요 .\n",
            "==============================\n"
          ]
        }
      ]
    }
  ]
}