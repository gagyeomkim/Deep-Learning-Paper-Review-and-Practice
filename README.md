## 딥러닝 논문 리뷰 &amp; 코드 실습: Deep-Learning-Paper-Review-and-Practice
- 딥러닝 논문 리뷰 및 코드 실습을 진행한 저장소입니다.

### **Computer Vision(컴퓨터비전)**

- [GoogLeNet] Going deeper with convolutions (2014)
  - [Paper Link](https://arxiv.org/abs/1409.4842) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/GoogleNet-Going-deeper-with-convolutions-1a5ab43529d980cf904fc72b9b4b11c8?source=copy_link) | [Summary] | [Code Practice](code_practice/GoogLeNet/GoogLeNet.ipynb)



### **Natural Language Processing (자연어 처리)**
- [Word2Vec1] Efficient Estimation of Word Representations in Vector Space (2013)
  - [Paper Link](https://arxiv.org/abs/1301.3781) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Word2Vec-1-Efficient-Estimation-of-Word-Representations-in-Vector-Space-20aab43529d98061ab00edd5a863a81d?source=copy_link) | [Summary] | [Code Practice](code_practice/Word2Vec/Word2Vec1.ipynb)

- [Word2Vec2] Distributed Representations of Words and Phrases and their Compositionality (2013)
  - [Paper Link](https://arxiv.org/abs/1310.4546) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Word2Vec-2-Distributed-Representations-of-Words-and-Phrases-and-their-Compositionality-229ab43529d9802792fec9d34f4d4b75?source=copy_link) | [Summary] | [Code Practice](code_practice/Word2Vec/Word2Vec2.ipynb)

- [TextCNN] Convolutional Neural Networks for Sentence Classification(EMNLP 2014)
  - [Paper Link](https://arxiv.org/abs/1408.5882) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/TextCNN-Convolutional-Neural-Networks-for-Sentence-Classification-239ab43529d98054919de53a567fbece?source=copy_link) | [Summary] | [Code Practice](code_practice/TextCNN/TextCNN.ipynb)

- [Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)
  - [Paper Link](https://arxiv.org/abs/1409.3215) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Seq2Seq-Sequence-to-Sequence-Learning-with-Neural-Networks-229ab43529d9807ea187f49b4f733012?source=copy_link) |[Summary](summary_pdf/2025-07-03-Sequence‑to‑Sequence.pdf)| [Code Practice](code_practice/Seq2Seq/Sequence_to_Sequence_with_GRU.ipynb)

- [Attention] Neural Machine Translation by Jointly Learning to Align and Translate(2014)
  - [Paper Link](https://arxiv.org/abs/1409.0473) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Attention-Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate-229ab43529d980ae9800ff2f150c21b3?source=copy_link) | [Summary](summary_pdf/2025-07-04-Attention-Mechanism.pdf) | [Code Practice](code_practice/Attention/Sequence_to_Sequence_with_Attention.ipynb)

- [Transformer] Attention Is All You Need(2017)
  - [Paper Link](https://arxiv.org/abs/1706.03762) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Transformer-Attention-Is-All-You-Need-228ab43529d9801ca912da8d7aa52e77?source=copy_link) | [Summary](summary_pdf/2025-07-05-Transformer.pdf)  | [Code Practice](code_practice/Transformer/Transformer.ipynb)

- [BERT] Pre-training of Deep Bidirectional Transformers for Language Understanding(NAACL 2019)
  - [Paper Link](https://arxiv.org/abs/1810.04805) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/BERT-Pre-training-of-Deep-Bidirectional-Transformers-for-Language-Understanding-232ab43529d980439acefd1c4b1c1f3c?source=copy_link) | [Summary]  | [Code Practice]

**Ref**
- 모든 Summary 자료는 직접 작성하였으며, 사용된 설명 및 사진의 원 출처는 [딥러닝 파이토치 교과서](https://wikidocs.net/book/2788)의 공개 내용임을 밝힙니다.
