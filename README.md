## 딥러닝 논문 리뷰 &amp; 코드 실습: Deep-Learning-Paper-Review-and-Practice
- 딥러닝 논문 리뷰 및 코드 실습을 진행한 저장소입니다.

### **Computer Vision(컴퓨터비전)**

- [GoogLeNet] Going deeper with convolutions (2014)
  - [Paper Link](https://arxiv.org/abs/1409.4842) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/GoogleNet-Going-deeper-with-convolutions-1a5ab43529d980cf904fc72b9b4b11c8?source=copy_link) | [Summary] | [Code Practice](code_practice/GoogLeNet.ipynb)



### **Natural Language Processing (자연어 처리)**
- [Word2Vec1] Efficient Estimation of Word Representations in Vector Space (2013)
  - [Paper Link](https://arxiv.org/abs/1301.3781) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Word2Vec-1-Efficient-Estimation-of-Word-Representations-in-Vector-Space-20aab43529d98061ab00edd5a863a81d?source=copy_link) | [Summary] | [Code Practice](code_practice/Word2Vec_Skip_gram.ipynb)
 
- [Word2Vec2: Skip-gram] Distributed Representations of Words and Phrases and their Compositionality (2013)
  - [Paper Link](https://arxiv.org/abs/1310.4546) | [Paper Review] | [Summary] | [Code Practice]

- [Seq2Seq] Sequence to Sequence Learning with Neural Networks (2014)
  - [Paper Link](https://arxiv.org/abs/1409.3215) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Seq2Seq-Sequence-to-Sequence-Learning-with-Neural-Networks-229ab43529d9807ea187f49b4f733012?source=copy_link) |[Summary](summary_pdf/2025-07-03-Sequence‑to‑Sequence.pdf)| [Code Practice](code_practice/Sequence_to_Sequence_with_GRU.ipynb)

- [Attention] Neural Machine Translation by Jointly Learning to Align and Translate(2014)
  - [Paper Link](https://arxiv.org/abs/1409.0473) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Attention-Neural-Machine-Translation-by-Jointly-Learning-to-Align-and-Translate-229ab43529d980ae9800ff2f150c21b3?source=copy_link) | [Summary](summary_pdf/2025-07-04-Attention-Mechanism.pdf) | [Code Practice](code_practice/Sequence_to_Sequence_with_Attention.ipynb)

- [Transformer] Attention Is All You Need(2017)
  - [Paper Link](https://arxiv.org/abs/1706.03762) | [Paper Review](https://deep-learning-paper-review-and-practice.notion.site/Transformer-Attention-Is-All-You-Need-228ab43529d9801ca912da8d7aa52e77?source=copy_link) | [Summary](summary_pdf/2025-07-05-Transformer.pdf)  | [Code Practice](code_practice/Transformer.ipynb)

**Ref**
- 모든 Summary 자료는 직접 작성하였으며, 사용된 설명 및 사진의 원 출처는 [딥러닝 파이토치 교과서](https://wikidocs.net/book/2788)의 공개 내용임을 밝힙니다.
